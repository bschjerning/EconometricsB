{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 2\n",
    "Before we start working on some exercises we will briefly introduce two concepts in Python. First, importing and exporting data. Second, using functions. If you are already familiar\n",
    "with these features, you can skip the next two sections and jump directly to the exercises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, import all necessary packages. We have made a .py file that we will use as a \"toolbox\". We will fill this toolbox with functions, that we will use as we progress through the course. Exactly how you structure this toolbox is up to you (if you i.e. want to turn it into a class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Import this weeks LinearModels .py file\n",
    "import LinearModelsPS2_post as lm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and exporting data in Python\n",
    "The easiest way to import data into an numpy array is using a .txt file. Normally we specify a path to the text file, but we will create a fake one to illustrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake file looks like this: \n",
      " 0 1\n",
      " 2 3\n",
      "\n",
      "Loaded into a numpy array, we get the following <class 'numpy.ndarray'>: \n",
      " [[0. 1.]\n",
      " [2. 3.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a fake file for easy use.\n",
    "fake_file = StringIO(\"0 1\\n 2 3\")\n",
    "print(f\"Fake file looks like this: \\n {fake_file.getvalue()}\")\n",
    "print()\n",
    "\n",
    "# Load the fake txt file into a numpy array.\n",
    "data = np.loadtxt(fake_file)\n",
    "print(f'Loaded into a numpy array, we get the following {type(data)}: \\n {data}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sadly, there is no direct way to load an excel sheet into numpy. The easiest solution is to use pandas as an intermediate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [2 3]]\n"
     ]
    }
   ],
   "source": [
    "# We save the fake file we created earlier as an excel file, \n",
    "# so that we can illustrate how to import using excel.\n",
    "to_export = pd.DataFrame(data)\n",
    "to_export.to_excel('test_file.xlsx', header=None, index=None)\n",
    "\n",
    "# Its important to note that Pandas will treat the first row as a header. If there is no header,\n",
    "# this needs to be specified. There are also alot of extra options to load specific sheets, or\n",
    "# only parts of the sheets and tons of extra options.\n",
    "df_import = pd.read_excel('test_file.xlsx', header=None)\n",
    "np_array = df_import.to_numpy()\n",
    "print(np_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data\n",
    "To save a numpy array as a .txt file is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.savetxt('real_file.txt', np_array)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If one has large numpy arrays and wants to store them efficiently, they can be saved as a binary .npy files. Such files are not compatible with other programs.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises with FE - Within-Groups Estimation\n",
    "\n",
    "The exercise takes up the union membership example from before. The data set WAGEPAN.TXT contains information about 545 men who worked every year from 1980 to 1987 in the US. The variables of interest are\n",
    "\n",
    "\n",
    "| Variable | Content |\n",
    "|-|-|\n",
    "| nr | Variable that identifies the individual  |\n",
    "| year | Year of observation |\n",
    "| Black | Black |\n",
    "| Hisp | Hispanic |\n",
    "| Educ | Years of schooling |\n",
    "| Exper | Years since left school |\n",
    "| Expersq | Exper2 |\n",
    "| Married | Marital status |\n",
    "| Union | Union membership |\n",
    "| Lwage | Natural logarithm of hourly wages |\n",
    "\n",
    "Consider the following wage equation:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\log\\left(wage_{it}\\right) & =\\beta_{0}+\\beta_{1}\\textit{exper}_{it}+\\beta_{2}\\textit{exper}_{it}^{2}+\\beta_{3}\\textit{union}_{it}+\\beta_{4}\\textit{married}_{i} +\\beta_{5}\\textit{educ}_{i}+\\beta_{6}\\textit{hisp}_{i}+\\beta_{7}\\textit{black}_{i}+c_{i}+u_{it} \\tag{1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that *educ*, *hisp*, and *black* are time-invariant variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FE Questions\n",
    "### FE (a):\n",
    "- **Estimate (1) by pooled OLS,** thus considering for the moment the unobserved components of (1) as one (composite) error term $v_{it}=c_{i}+u_{it}$. \n",
    "- What assumptions are made about $E\\left[c_{i}\\mathbf{x}_{it}\\right]$ and $E\\left[u_{it}\\mathbf{x}_{it}\\right]$ when justifying this estimation approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, import the data into numpy. \n",
    "data = np.loadtxt('wagepan.txt', delimiter=\",\")\n",
    "id_array = np.array(data[:, 0])\n",
    "\n",
    "# Count how many persons we have. This returns a tuple with the unique IDs,\n",
    "# and the number of times each person is observed.\n",
    "unique_id = np.unique(id_array, return_counts=True)\n",
    "N = unique_id[0].size\n",
    "T = int(unique_id[1].mean())\n",
    "year = np.array(data[:, 1], dtype=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above does not correspond 1:1 with the text file. The data has 10 columns. Named from 0 to 9. Here is a variable describtion:\n",
    "- Column 0: ID\n",
    "- Column 1: Year\n",
    "- Column 2: Black\n",
    "- Column 3: Experience\n",
    "- Column 4: Hispanic\n",
    "- Column 5: Married\n",
    "- Column 6: Education\n",
    "- Column 7: Union\n",
    "- Column 8: ln wage\n",
    "- Column 9: Experience sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the rest of the data into arrays.\n",
    "y = np.array(data[:, 8]).reshape(-1, 1)\n",
    "x = np.array(\n",
    "    [np.ones((y.shape[0])), \n",
    "    data[:, 2],\n",
    "    data[:, 4],\n",
    "    data[:, 6],\n",
    "    data[:, 3],\n",
    "    data[:, 9],\n",
    "    data[:, 5],\n",
    "    data[:, 7]]\n",
    ").T\n",
    "\n",
    "# Lets also make some variable names\n",
    "label_y = 'Log wage'\n",
    "label_x = [\n",
    "    'Constant', \n",
    "    'Black', \n",
    "    'Hispanic', \n",
    "    'Education', \n",
    "    'Experience', \n",
    "    'Experience sqr', \n",
    "    'Married', \n",
    "    'Union'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled OLS\n",
      "Dependent variable: Log wage\n",
      "\n",
      "                   Beta      Se    t-values\n",
      "--------------  -------  ------  ----------\n",
      "Constant        -0.0347  0.0646     -0.5375\n",
      "Black           -0.1438  0.0236     -6.1055\n",
      "Hispanic         0.0157  0.0208      0.7543\n",
      "Education        0.0994  0.0047     21.2476\n",
      "Experience       0.0892  0.0101      8.8200\n",
      "Experience sqr  -0.0028  0.0007     -4.0272\n",
      "Married          0.1077  0.0157      6.8592\n",
      "Union            0.1801  0.0171     10.5179\n",
      "R² = 0.187\n",
      "σ² = 0.231\n"
     ]
    }
   ],
   "source": [
    "ols_result = lm.estimate(y, x,N=N,T=T)\n",
    "lm.print_table(\n",
    "    (label_y, label_x), ols_result, title=\"Pooled OLS\", floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "Pooled OLS <br>\n",
    "Dependent variable: Log wage <br>\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Constant       | -0.0347 | 0.0646 |    -0.5375 |\n",
    "| Black          | -0.1438 | 0.0236 |    -6.1055 |\n",
    "| Hispanic       |  0.0157 | 0.0208 |     0.7543 |\n",
    "| Education      |  0.0994 | 0.0047 |    21.2476 |\n",
    "| Experience     |  0.0892 | 0.0101 |     8.8200 |\n",
    "| Experience sqr | -0.0028 | 0.0007 |    -4.0272 |\n",
    "| Married        |  0.1077 | 0.0157 |     6.8592 |\n",
    "| Union          |  0.1801 | 0.0171 |    10.5179 |\n",
    "R² = 0.187 <br>\n",
    "σ² = 0.231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FE (b):\n",
    "- Within transform the data. What happens to *educ, hisp, and black* and $x_{it1}\\equiv1$ when the data are within transformed? \n",
    "- What is the rank of the within transformed $\\mathbf{X}$ matrix? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demeaning_matrix(T):\n",
    "    Q_T = np.eye(T) - np.tile(1/T, (T, T))\n",
    "    return Q_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of demeaned x: 4\n",
      "Eigenvalues of within-transformed x: [4248875.    1871.     365.     329.       0.       0.       0.       0.]\n"
     ]
    }
   ],
   "source": [
    "Q_T = demeaning_matrix(T)\n",
    "y_demean = lm.perm(Q_T, y)\n",
    "x_demean = lm.perm(Q_T, x)\n",
    "\n",
    "# Check rank of demeaned matrix, and return its eigenvalues.\n",
    "def check_rank(x):\n",
    "    print(f'Rank of demeaned x: {la.matrix_rank(x)}')\n",
    "    lambdas, V = la.eig(x.T@x)\n",
    "    np.set_printoptions(suppress=True)  # This is just to print nicely.\n",
    "    print(f'Eigenvalues of within-transformed x: {lambdas.round(decimals=0)}')\n",
    "check_rank(x_demean)\n",
    "\n",
    "# We need to drop the columns that are constant over time.\n",
    "# Try to first estimate the OLS without removing the 0-columns.\n",
    "x_demean = x_demean[:, 4:]\n",
    "label_x_fe = label_x[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the perm function is to use panda dataframes to group the data. This has been done for the *entire* dataset below. If you want to use this method you'll need to make sure to pull out the correct variables when computing first difference and fixed effects estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data using pandas\n",
    "pddat = pd.read_csv('wagepan.txt', delimiter=\",\", header=None)\n",
    "pddat.columns = [\"ID\", \"year\", \"black\", \"exp\", \"hisp\", \"mar\", \"educ\", \"union\", \"logwage\", \"expsq\"]\n",
    "\n",
    "# first difference the data\n",
    "pddat = pddat.sort_values([\"ID\", \"year\"]) # important to ensure years are sorted correctly\n",
    "pddat_diff = pddat.groupby(\"ID\").diff().dropna() # take differences and drop NaNs due to differencing\n",
    "datdiff = pddat_diff.to_numpy() # turn into numpy array\n",
    "\n",
    "# demean data\n",
    "pddat_demean=pddat-pddat.groupby(\"ID\").transform('mean')\n",
    "datdemean = pddat_demean.to_numpy() # turn into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>black</th>\n",
       "      <th>exp</th>\n",
       "      <th>hisp</th>\n",
       "      <th>mar</th>\n",
       "      <th>educ</th>\n",
       "      <th>union</th>\n",
       "      <th>logwage</th>\n",
       "      <th>expsq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.655520</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.508598</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088752</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134912</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131766</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.759397</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.379336</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.553419</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.020068</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.279351</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3815 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      year  black  exp  hisp  mar  educ  union   logwage  expsq\n",
       "1      1.0    0.0  1.0   0.0  0.0   0.0    1.0  0.655520    3.0\n",
       "2      1.0    0.0  1.0   0.0  0.0   0.0   -1.0 -0.508598    5.0\n",
       "3      1.0    0.0  1.0   0.0  0.0   0.0    0.0  0.088752    7.0\n",
       "4      1.0    0.0  1.0   0.0  0.0   0.0    0.0  0.134912    9.0\n",
       "5      1.0    0.0  1.0   0.0  0.0   0.0    0.0  0.131766   11.0\n",
       "...    ...    ...  ...   ...  ...   ...    ...       ...    ...\n",
       "4355   1.0    0.0  1.0   0.0  1.0   0.0    0.0  0.759397   15.0\n",
       "4356   1.0    0.0  1.0   0.0  0.0   0.0    1.0 -0.379336   17.0\n",
       "4357   1.0    0.0  1.0   0.0  0.0   0.0   -1.0  0.553419   19.0\n",
       "4358   1.0    0.0  1.0   0.0  0.0   0.0    1.0 -0.020068   21.0\n",
       "4359   1.0    0.0  1.0   0.0  0.0   0.0    0.0 -0.279351   23.0\n",
       "\n",
       "[3815 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can look at the dataframe to see where the relevant variables are, note dimensions\n",
    "pddat_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ydiff = np.array(datdiff[:, 7]).reshape(-1, 1)\n",
    "xdiff = np.array([\n",
    "    datdiff[:, 2],\n",
    "    datdiff[:, 8],\n",
    "    datdiff[:, 4],\n",
    "    datdiff[:, 6]]\n",
    ").T\n",
    "la.matrix_rank(xdiff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>black</th>\n",
       "      <th>educ</th>\n",
       "      <th>exp</th>\n",
       "      <th>expsq</th>\n",
       "      <th>hisp</th>\n",
       "      <th>logwage</th>\n",
       "      <th>mar</th>\n",
       "      <th>union</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-24.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.058112</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-21.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.597408</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088810</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.177561</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312473</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.125</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4355</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209697</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>-0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.169639</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4357</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383780</td>\n",
       "      <td>0.375</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4358</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>43.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363713</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>66.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084362</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.625</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4360 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  black  educ  exp  expsq  hisp   logwage    mar  union  year\n",
       "0    NaN    0.0   0.0 -3.5  -24.5   0.0 -0.058112  0.000 -0.125  -3.5\n",
       "1    NaN    0.0   0.0 -2.5  -21.5   0.0  0.597408  0.000  0.875  -2.5\n",
       "2    NaN    0.0   0.0 -1.5  -16.5   0.0  0.088810  0.000 -0.125  -1.5\n",
       "3    NaN    0.0   0.0 -0.5   -9.5   0.0  0.177561  0.000 -0.125  -0.5\n",
       "4    NaN    0.0   0.0  0.5   -0.5   0.0  0.312473  0.000 -0.125   0.5\n",
       "...   ..    ...   ...  ...    ...   ...       ...    ...    ...   ...\n",
       "4355 NaN    0.0   0.0 -0.5  -13.5   0.0  0.209697  0.375 -0.375  -0.5\n",
       "4356 NaN    0.0   0.0  0.5    3.5   0.0 -0.169639  0.375  0.625   0.5\n",
       "4357 NaN    0.0   0.0  1.5   22.5   0.0  0.383780  0.375 -0.375   1.5\n",
       "4358 NaN    0.0   0.0  2.5   43.5   0.0  0.363713  0.375  0.625   2.5\n",
       "4359 NaN    0.0   0.0  3.5   66.5   0.0  0.084362  0.375  0.625   3.5\n",
       "\n",
       "[4360 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can look at the dataframe to see where the relevant variables are, note dimensions\n",
    "pddat_demean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dot = np.array(datdemean[:, 6]).reshape(-1, 1)\n",
    "x_dot = np.array([\n",
    "    datdemean[:, 3],\n",
    "    datdemean[:, 4],\n",
    "    datdemean[:, 7],\n",
    "    datdemean[:, 8]]\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FE (c):\n",
    "- Estimate (1) on within transformed data (make sure that the employed $\\mathbf{\\ddot{X}}$ has full rank - drop columns if necessary). \n",
    "- How big is the union premium according to the estimate from the FE model? Compare this with the estimate that you calculated from the pooled OLS regression. What does this suggest about $E\\left[union_{it}c_{i}\\right]$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE regression\n",
      "Dependent variable: Log wage\n",
      "\n",
      "                   Beta      Se    t-values\n",
      "--------------  -------  ------  ----------\n",
      "Experience       0.1168  0.0084     13.8778\n",
      "Experience sqr  -0.0043  0.0006     -7.1057\n",
      "Married          0.0453  0.0183      2.4743\n",
      "Union            0.0821  0.0193      4.2553\n",
      "R² = 0.178\n",
      "σ² = 0.123\n"
     ]
    }
   ],
   "source": [
    "# Estimate FE OLS using the demeaned variables.\n",
    "fe_result = lm.estimate(\n",
    "    y_dot, x_dot, transform='fe', N=N, T=T # could also use y_demean, x_demean from perm function\n",
    ")\n",
    "lm.print_table(\n",
    "    (label_y, label_x_fe), \n",
    "    fe_result, title='FE regression', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "FE regression<br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1168 | 0.0084 |    13.8778 |\n",
    "| Experience sqr | -0.0043 | 0.0006 |    -7.1057 |\n",
    "| Married        |  0.0453 | 0.0183 |     2.4743 |\n",
    "| Union          |  0.0821 | 0.0193 |     4.2553 |\n",
    "R² = 0.178 <br>\n",
    "σ² = 0.123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FD Questions\n",
    "### FD (a):\n",
    "- Construct $\\mathbf{D}$ and use the procedure `perm` $(\\mathbf{D},\\mathbf{x})$ to compute first differences of the elements of $\\mathbf{y}$ and $\\mathbf{x}$. \n",
    "- What happens to *educ, hisp* and *black* and $x_{it1}\\equiv1$ when the data are transformed into first differences? What is the rank of the first differenced $\\mathbf{x}$-matrix? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_matrix(T):\n",
    "    D_T = np.eye(T) - np.eye(T, k=-1)\n",
    "    D_T = D_T[1:]\n",
    "    return D_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of demeaned x: 4\n",
      "Eigenvalues of within-transformed x: [753711.    356.    545.    508.      0.      0.      0.      0.]\n"
     ]
    }
   ],
   "source": [
    "# Transform the data.\n",
    "D_T = fd_matrix(T)\n",
    "y_diff = lm.perm(D_T, y)\n",
    "x_diff = lm.perm(D_T, x)\n",
    "\n",
    "# Again, check rank condition.\n",
    "check_rank(x_diff)\n",
    "\n",
    "# Remember to remove linear dependent columns\n",
    "x_diff = x_diff[:, 4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FD (b):\n",
    "- Estimate (1) in first differences. How big is the union premium according to the estimate from this model? \n",
    "- Compare the FD estimate with the estimate that you calculated from the FE regression. Is there a difference? If yes, what (if anything) can we conclude based on this finding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD regression\n",
      "Dependent variable: Log wage\n",
      "\n",
      "                   Beta      Se    t-values\n",
      "--------------  -------  ------  ----------\n",
      "Experience       0.1158  0.0196      5.9096\n",
      "Experience sqr  -0.0039  0.0014     -2.8005\n",
      "Married          0.0381  0.0229      1.6633\n",
      "Union            0.0428  0.0197      2.1767\n",
      "R² = 0.004\n",
      "σ² = 0.196\n"
     ]
    }
   ],
   "source": [
    "fd_result = lm.estimate(\n",
    "    ydiff, xdiff, N=N, T=T-1 # could also use y_diff, x_diff from perm function\n",
    ")\n",
    "lm.print_table(\n",
    "    (label_y, label_x_fe), \n",
    "    fd_result, title='FD regression', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "FD regression <br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1158 | 0.0196 |     5.9096 |\n",
    "| Experience sqr | -0.0039 | 0.0014 |    -2.8005 |\n",
    "| Married        |  0.0381 | 0.0229 |     1.6633 |\n",
    "| Union          |  0.0428 | 0.0197 |     2.1767 |\n",
    "R² = 0.004 <br>\n",
    "σ² = 0.196"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise comparing FE and FD\n",
    "### Question FE v. FD (a):\n",
    "**Test for serial correlation in the errors using an auxilliary AR(1) model**, to test assumption FD.3, where the errors $e_{it} = \\Delta u_{it}$ should be serially uncorrelated.\n",
    "\n",
    "We can easily test this assumption given the OLS residuals from the FD version of equation (1). Run the regression (note that you will loose data for\n",
    "the *two* first periods)\n",
    "\\begin{equation}\n",
    "\\hat{e}_{it}=\\rho\\hat{e}_{it-1}+error_{it},\\quad t=\\color{red}{3},\\dotsc,T,\\quad i=1,\\dotsc,N\\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Do you find any evidence for serial correlation? Does FD.3 seem appropriate? And why don't we include an intercept in this auxilliary equation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* Under FE.3, the idiosyncratic errors $u_{it}$\n",
    "are uncorrelated. However, FE.3 implies that the $e_{it}$'s are autocorrelated. In fact, of the $u_{it}$'s are serially uncorrelated to beging with, corr$\\left(e_{it},e_{it-1}\\right)=-0.5$. (Check!) This test is of course only valid if the explanatory variables are strictly exogenous!\n",
    "\n",
    "*Hint:* You can use the `perm` function to lag\n",
    "the error term variable. Consider the following; \n",
    "\n",
    "$$\n",
    "{\\begin{bmatrix}\n",
    "1 & 0 & 0 & \\cdots & 0 & 0\\\\\n",
    "0 & 1 & 0 & \\cdots & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\cdots & 1 & 0\n",
    "\\end{bmatrix}}_{T-1\\times T}\\times{\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T}\n",
    "\\end{bmatrix}}_{T \\times 1}={\\begin{bmatrix}y_{1}\\\\\n",
    "y_{2}\\\\\n",
    "\\vdots\\\\\n",
    "y_{T - 1}\n",
    "\\end{bmatrix}}_{T - 1\\times 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serial_corr(y, x, T, year):\n",
    "    b_hat = lm.est_ols(y, x)\n",
    "    e = y - x@b_hat\n",
    "    \n",
    "    # Create a lag to estimate the error on.\n",
    "    L_T = np.eye(T, k=-1)\n",
    "    L_T = L_T[1:]\n",
    "\n",
    "    e_l = lm.perm(L_T, e)\n",
    "\n",
    "    # We then need to remove the first obs for every person again.\n",
    "    reduced_year = year[year != 1980]\n",
    "    e = e[reduced_year != 1981]\n",
    "\n",
    "    return lm.estimate(e, e_l,N=N,T=T-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serial Correlation\n",
      "Dependent variable: OLS residual, eᵢₜ\n",
      "\n",
      "          Beta      Se    t-values\n",
      "-----  -------  ------  ----------\n",
      "eᵢₜ₋₁  -0.3961  0.0147    -27.0185\n",
      "R² = 0.182\n",
      "σ² = 0.143\n"
     ]
    }
   ],
   "source": [
    "corr_result = serial_corr(y_diff, x_diff, T-1, year)\n",
    "\n",
    "label_ye = 'OLS residual, e\\u1d62\\u209c'\n",
    "label_e = ['e\\u1d62\\u209c\\u208B\\u2081']\n",
    "title = 'Serial Correlation'\n",
    "lm.print_table(\n",
    "    (label_ye, label_e), corr_result, \n",
    "    title='Serial Correlation', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "Serial Correlation <br>\n",
    "Dependent variable: OLS residual, eᵢₜ\n",
    "\n",
    "|       |    Beta |     Se |   t-values |\n",
    "|-------|---------|--------|------------|\n",
    "| eᵢₜ₋₁ | -0.3961 | 0.0147 |   -27.0185 |\n",
    "R² = 0.182 <br>\n",
    "σ² = 0.143"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question FE v FD (b):\n",
    "\n",
    "Test for strict exogeneity: Add a lead of the union variable, $union_{i,t+1}$ to equation (1) (note that you will lose data from period $T$ , 1987) and estimate the model with *fixed effects* (i.e., you have to demean $union_{i,t+1}$ along with all the other variables and throw out time constant variables). Is $union_{i,t+1}$ significant? What does this imply for the strict exogeneity assumption?\n",
    "\n",
    "*Hint:* To lead a variable, think along the same lines as in Question FE v FD (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exogeneity test\n",
      "Dependent variable: Log wage\n",
      "\n",
      "                   Beta      Se    t-values\n",
      "--------------  -------  ------  ----------\n",
      "Experience       0.1213  0.0100     12.1001\n",
      "Experience sqr  -0.0050  0.0008     -6.3579\n",
      "Married          0.0436  0.0209      2.0898\n",
      "Union            0.0757  0.0218      3.4784\n",
      "Union lead       0.0515  0.0223      2.3063\n",
      "R² = 0.146\n",
      "σ² = 0.128\n"
     ]
    }
   ],
   "source": [
    "def exogeneity_test(x, y, T):\n",
    "    # Create lead\n",
    "    F_T = np.eye(T, k=1)\n",
    "    F_T = F_T[:-1]\n",
    "\n",
    "    # Lead union\n",
    "    union_lead = lm.perm(F_T, x[:, 7].reshape(-1, 1))\n",
    "\n",
    "    # Collect variables to test for exogeneity\n",
    "    x_exo = x[year != 1987]\n",
    "    x_exo = np.hstack((x_exo, union_lead))\n",
    "    y_exo = y[year != 1987]\n",
    "\n",
    "    # Within transform the data\n",
    "    Q_T = demeaning_matrix(T - 1)\n",
    "\n",
    "    yw_exo = lm.perm(Q_T, y_exo)\n",
    "    xw_exo = lm.perm(Q_T, x_exo)\n",
    "    xw_exo = xw_exo[:, 4:]\n",
    "\n",
    "    label_exo = label_x_fe + ['Union lead']\n",
    "    n = y.size/T\n",
    "    # Estimate model\n",
    "    exo_test = lm.estimate(\n",
    "        yw_exo, xw_exo, N=N, T=T - 1, transform='fe'\n",
    "    )\n",
    "    # Adjust sigma2 since\n",
    "\n",
    "    lm.print_table(\n",
    "        (label_y, label_exo), \n",
    "        exo_test, title='Exogeneity test', floatfmt='.4f'\n",
    "    )\n",
    "exogeneity_test(x, y, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table should look something like this:\n",
    "Exogeneity test <br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1213 | 0.0100 |    12.1001 |\n",
    "| Experience sqr | -0.0050 | 0.0008 |    -6.3579 |\n",
    "| Married        |  0.0436 | 0.0209 |     2.0898 |\n",
    "| Union          |  0.0757 | 0.0218 |     3.4784 |\n",
    "| Union lead     |  0.0515 | 0.0223 |     2.3063 |\n",
    "R² = 0.146<br>\n",
    "σ² = 0.128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question FE v FD (b):\n",
    "Add interactions on the form $d_{81}\\cdot educ, d_{82}\\cdot educ, ..., d_{87}\\cdot educ$ and estimate the model with fixed effect. Has the return to education increased over time?\n",
    "\n",
    "*Hint:* Remember that $educ_{i}$ doesn't vary over\n",
    "time! Therefore we didn't use $educ$ in levels in the FE estimation.\n",
    "However, if we suppose that the structural equation (4) contains a term $\\sum_{s=2}^{T}\\delta_{s}d_{s}educ_{i}$, it will be perfectly fine to within-transform these interactions since they vary over time (although in a highly structured manner - they equal\n",
    "zero in all time periods but one, and then $educ$). Note that one\n",
    "period is dropped for the within-transformation to work whereas the\n",
    "levels term, $\\beta_{5}educ_{i}$, is dropped to avoid producing a\n",
    "constant row.\n",
    "\n",
    "*Programming hint:* You want to append the dataset with a dummy matrix, that would look something like this:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "14 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 14 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 14 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "9 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 9 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This example shows our two first persons, that have 14 and 9 years of education respectively. This matrix can be created as a product of two matrices, what would they look like (a dummy matrix with onlyn ones can be creates using `np.eye` and `np.tile`)? Why is the first row for each person only zeros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This dummy block has a 0 row, as we need to exclude one\n",
    "# year in order to not end up in the dummy trap.\n",
    "dummy_block = np.eye(T, k=-1)[:, :-1]\n",
    "\n",
    "# Expand thid dummy block to all persons\n",
    "dummy_matrix = np.tile(dummy_block, (N, 1))\n",
    "\n",
    "# We now create a n*t-1 matrix, with the person's education \n",
    "expanded_educ = np.transpose([x[:, 3]] * (T-1))\n",
    "\n",
    "# We can now multiplu the year dummy with a person's education\n",
    "educ_dummies = dummy_matrix*expanded_educ\n",
    "educ_demean = lm.perm(Q_T, educ_dummies)\n",
    "x_demean_dummies = np.hstack([x_demean, educ_demean])\n",
    "\n",
    "label_x_interactions = label_x_fe + [\n",
    "    'E81', 'E82', 'E83', 'E84', 'E85', 'E86', 'E87'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FE with year interactions\n",
      "Dependent variable: Log wage\n",
      "\n",
      "                   Beta      Se    t-values\n",
      "--------------  -------  ------  ----------\n",
      "Experience       0.1705  0.0273      6.2462\n",
      "Experience sqr  -0.0060  0.0009     -6.9581\n",
      "Married          0.0475  0.0183      2.5925\n",
      "Union            0.0794  0.0193      4.1138\n",
      "E81             -0.0010  0.0026     -0.4009\n",
      "E82             -0.0062  0.0041     -1.5224\n",
      "E83             -0.0114  0.0057     -2.0006\n",
      "E84             -0.0136  0.0072     -1.8787\n",
      "E85             -0.0162  0.0087     -1.8578\n",
      "E86             -0.0170  0.0101     -1.6804\n",
      "E87             -0.0167  0.0115     -1.4619\n",
      "R² = 0.181\n",
      "σ² = 0.123\n"
     ]
    }
   ],
   "source": [
    "int_result = lm.estimate(\n",
    "    y_demean, x_demean_dummies, transform='fe', N=N, T=T\n",
    ")\n",
    "lm.print_table(\n",
    "    (label_y, label_x_interactions), int_result, \n",
    "    title='FE with year interactions', floatfmt='.4f'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get a table that looks like this:\n",
    "\n",
    "FE with year interactions <br>\n",
    "Dependent variable: Log wage\n",
    "\n",
    "|                |    Beta |     Se |   t-values |\n",
    "|----------------|---------|--------|------------|\n",
    "| Experience     |  0.1705 | 0.0273 |     6.2462 |\n",
    "| Experience sqr | -0.0060 | 0.0009 |    -6.9581 |\n",
    "| Married        |  0.0475 | 0.0183 |     2.5925 |\n",
    "| Union          |  0.0794 | 0.0193 |     4.1138 |\n",
    "| E81            | -0.0010 | 0.0026 |    -0.4009 |\n",
    "| E82            | -0.0062 | 0.0041 |    -1.5224 |\n",
    "| E83            | -0.0114 | 0.0057 |    -2.0006 |\n",
    "| E84            | -0.0136 | 0.0072 |    -1.8787 |\n",
    "| E85            | -0.0162 | 0.0087 |    -1.8578 |\n",
    "| E86            | -0.0170 | 0.0101 |    -1.6804 |\n",
    "| E87            | -0.0167 | 0.0115 |    -1.4619 |\n",
    "R² = 0.181 <br>\n",
    "σ² = 0.123"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7e955f0f740a88143167821a8b0fbd15a506d043cd936f8554468bc13302d823"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
