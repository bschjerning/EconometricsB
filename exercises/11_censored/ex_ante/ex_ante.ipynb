{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem set 11: Tobit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from numpy import linalg as la\n",
    "from scipy.stats import norm\n",
    "from scipy import optimize\n",
    "from tabulate import tabulate\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns \n",
    "sns.set_theme()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tobit\n",
    "import estimation\n",
    "import LinearModels as lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate Data\n",
    "\n",
    "1. Fill out `tobit.sim_data(theta,N)` and simulate a dataset\n",
    "2. Fill out `tobit.predict(theta, x)`, returning `E, Epos`: \n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathbb{E}(y_{i}|\\mathbf{x}_{i})\t&=\t\\mathbf{x}_{i}\\beta\\Phi\\left(\\frac{\\mathbf{x}_{i}\\beta}{\\sigma}\\right)+\\sigma\\phi\\left(\\frac{\\mathbf{x}_{i}\\beta}{\\sigma}\\right),\n",
    "\\\\\n",
    "\\mathbb{E}(y_{i}|\\mathbf{x}_{i},y_{i}>0)\t&=\t\\mathbf{x}_{i}\\beta+\\sigma\\lambda\\left(\\frac{\\mathbf{x}_{i}\\beta}{\\sigma}\\right).\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "betao = np.array([1.,1.])\n",
    "sigo = 1.\n",
    "thetao = np.append(betao, sigo) # since sigo is scalar, use np.append() rather than np.stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "y,x = tobit.sim_data(thetao, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E, Epos = tobit.predict(thetao, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots();\n",
    "ax.plot(x[:, 1], y, 'o', alpha=0.3, label='y');\n",
    "ax.plot(x[:, 1], E,    '.r', label='E(y|x)')\n",
    "ax.plot(x[:, 1], Epos, '.g', label='E(y|x, y>0)')\n",
    "ax.plot(x[:, 1], x@betao,  '.y', label='$x \\\\beta$')\n",
    "ax.set_title('Simulated data'); ax.set_xlabel('$x_2$'); ax.set_ylabel('$y$');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "\n",
    "1. Fill out `tobit.starting_values(y,x)`: base starting values of $\\boldsymbol{\\theta} = (\\boldsymbol{\\beta}, \\sigma)$ on OLS counterparts; even though they are inconsistent, they are somewhat in the ballpark. Note that we will be estimating $\\sigma$ and not $\\sigma^2$.  \n",
    "2. Finish writing the criterion function, `q(theta, y, x)` based on `loglikelihood(theta, y, x)`, in the `tobit.py` based on the likelihood function $$ \n",
    "\\ell_i(\\theta) = \\mathbf{1}\\{y_i = 0\\} \\log\\left[1 - \\Phi\\left(\\frac{\\mathbf{x}_i \\boldsymbol{\\beta}}{\\sigma}\\right)\\right] \n",
    "               + \\mathbf{1}\\{y_i > 0\\} \\log\\left[\\frac{1}{\\sigma} \\phi\\left(\\frac{y_i - \\mathbf{x}_i \\boldsymbol{\\beta}}{\\sigma}\\right)\\right] $$\n",
    "3. Estimate the model on simulated data\n",
    "\n",
    "***Hints:***\n",
    "* For the normal CDF and PDF: Use `norm.cdf` and `norm.cdf` from `scipy.stats`\n",
    "* Since you are taking logs, it can be good practice to ensure that you are not taking log of zero. Use `np.clip(vec, 1e-8, 1.0-1e-8)`, for example, to ensure that `vec` is within $[0.00000001; 0.99999999]$\n",
    "* Force `sigma` to remain positive during estimation by taking `np.abs(sigma)` when unpacking parameters (in `loglikelihood`, e.g.)\n",
    "\n",
    "You can check if you got the correct result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = tobit.starting_values(y, x)\n",
    "theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the loglikelihood function \n",
    "ll0 = tobit.loglikelihood(theta0, y, x)\n",
    "\n",
    "# this can sometimes be off if your seed is not set or if your version is very different from \n",
    "# the one used by me (np.__version__ = 1.21.2)\n",
    "np.isclose( np.mean(ll0), -1.3433337203403535 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = estimation.estimate(tobit.q, theta0, y, x, cov_type='Sandwich')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results out in a neat table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {'theta_o': thetao, \n",
    "              'thetahat': res['theta'], \n",
    "              't': res['t']}\n",
    "lab_theta = ['x1', 'x2', 'sigma']\n",
    "\n",
    "pd.DataFrame(result_dict, index=lab_theta).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected results: Final function value: 1.288781, Function evaluations: 32. \n",
    "\n",
    "|       |   theta_o |   thetahat |      t |\n",
    "|:------|----------:|-----------:|-------:|\n",
    "| x1    |         1 |      1.022 | 30.107 |\n",
    "| x2    |         1 |      1.035 | 28.312 |\n",
    "| sigma |         1 |      1.029 | 42.137 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empirical analysis\n",
    "==================\n",
    "\n",
    "The exercise asks you to estimate a censored regression model for the\n",
    "number of working hours in the labour market, using the `mroz_hours.txt`\n",
    "dataset (same as PS04, with working hours). Working hours is a\n",
    "left-censored variable because the variable hours takes the value zero\n",
    "when no hours are put in the labour market. The data set\n",
    "`mroz_hours.txt` contains observations on 753 women for the following\n",
    "variables:\n",
    "\n",
    "|*Variable*  | *Definition*|\n",
    "|------------| ---------------------------------|\n",
    "|`Hours`     | Number of hours worked annually|\n",
    "|`Nwifeinc`  | Non wife income|\n",
    "|`Educ`      | Years of education|\n",
    "|`Exper`     | Experience in labour market|\n",
    "|`Expersq`   | Experience squared|\n",
    "|`Age`       | Age|\n",
    "|`Kidslt6`   | Number of kids aged 0--5|\n",
    "|`Kidsge6`   | Number of kids aged 6--18|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some of the columns are not documented; we name them n.a. X\n",
    "cols = ['hours', 'n.a. 1', 'nwifeinc', 'exper', 'expersq', 'age', 'kidslt6', 'kidsge6', \n",
    "        'n.a. 2', 'n.a. 3', 'n.a. 4', 'educ']\n",
    "\n",
    "# read dataset \n",
    "dat = pd.read_csv('mroz_hours.txt', header = None, names = cols)\n",
    "\n",
    "# add constant term \n",
    "dat['cnst'] = 1.0\n",
    "\n",
    "# Declare labels\n",
    "lbly = 'hours'\n",
    "lblx = ['cnst', 'nwifeinc', 'educ', 'exper', 'expersq', 'age', 'kidslt6', 'kidsge6']\n",
    "\n",
    "# pandas to numpy \n",
    "x = dat[lblx].values\n",
    "y = dat[lbly].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "As a preperation, plot y in a histogram. Does the distribution of hours worked look probelmatic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matbplotlib.pyplot module is already loaded for you as plt.\n",
    "# A hint is to use more bins than default, try for example 50 bins.\n",
    "# FILL IN: Plot a histogram of y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 \n",
    "\n",
    "Estimate by OLS a regression function of annual hours worked as a function of the variables (`cnst`, `nwifeinc, educ, exper, expersq, age, kidslt6, kidsge6`), using the `LinearModels` module. \n",
    "\n",
    "Check that your `tobit.starting_values()` function is getting the correct numbers in creating `theta0`: The first $K=8$ parameters are $\\boldsymbol{\\beta}$, and the last, 9th coefficient is $\\sigma$ (and not $\\sigma^2$!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = None \n",
    "sig = None\n",
    "theta0 = np.append(b, np.sqrt(sig)) # the structure of theta0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = tobit.starting_values(y, x) # using the tobit function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_results = lm.estimate(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'betahat': ols_results['b_hat'],\n",
    "     'se': ols_results['se'].flatten()}\n",
    "tab = pd.DataFrame(d, index=lblx)\n",
    "pd.concat((tab,pd.DataFrame({'betahat': sig, 'se': np.nan}, index=['sigma'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ols_results = None \n",
    "lm.print_table((lbly, lblx), ols_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2:\n",
    "1. Finish writing the criterion function, in the `toibt.py` based on the likelihood function $$ \n",
    "\\ell_i(\\theta) = \\mathbf{1}\\{y_i = 0\\} \\log\\left[1 - \\Phi\\left(\\frac{\\mathbf{x}_i \\boldsymbol{\\beta}}{\\sigma}\\right)\\right] \n",
    "               + \\mathbf{1}\\{y_i > 0\\} \\log\\left[\\frac{1}{\\sigma} \\phi\\left(\\frac{y_i - \\mathbf{x}_i \\boldsymbol{\\beta}}{\\sigma}\\right)\\right] $$\n",
    "2. Estimate the model \n",
    "\n",
    "***Hints:***\n",
    "* For the normal CDF and PDF: Use `norm.cdf` and `norm.cdf` from `scipy.stats`\n",
    "* Since you are taking logs, it can be good practice to ensure that you are not taking log of zero. Use `np.clip(vec, 1e-8, 1.0-1e-8)`, for example, to ensure that `vec` is within $[0.00000001; 0.99999999]$\n",
    "* Force `sigma` to remain positive during estimation by taking `np.abs(sigma)` when unpacking parameters. \n",
    "\n",
    "You can check if you got the correct result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isclose(\n",
    "    np.mean(tobit.loglikelihood(theta0, y, x))\n",
    "    , -5.257462977706353\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3:\n",
    "Estimate the corresponding Censored Regression Model by Maximum Likelihood. To do this, $\\texttt{[FILL IN]}$ the blanks in the `q` function in the `tobit` class and supply it to the `estimation.estimate()` function.\n",
    "\n",
    "Report also $\\hat{\\sigma}^{2}$ and $R_{\\mathrm{Tobit}}^{2}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = estimation.estimate(tobit.q, theta0, y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the $R_{\\mathrm{Tobit}}^{2}$, this is the squared correlation between $y_{i}$ and $\\hat{y}_{i}$, where $\\hat{y}_i = \\Phi (\\mathbf{x}_i \\hat{\\beta}/\\hat{\\sigma})\\mathbf{x}_i \\hat{\\beta} + \\hat{\\sigma}\\phi(\\mathbf{x}_i \\hat{\\beta}/\\hat{\\sigma})$, which is the estimate of $\\mathrm{E}\\left(y|\\mathbf{x}=\\mathbf{x}_{i}\\right )$\\] ($\\Phi$ is the normal cdf, and $\\phi$ is the normal pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R2\n",
    "sigma_tob = result.get('theta')[-1]\n",
    "sig_tob   = result.get('theta')[-1]\n",
    "b_tob     = result.get('theta')[:-1]\n",
    "b_se_tob  = result.get('se')[:-1]\n",
    "\n",
    "xb = x@b_tob\n",
    "y_hat = xb*norm.cdf(xb/sigma_tob) + sigma_tob*norm.pdf(xb/sigma_tob)\n",
    "rho = np.corrcoef(y.flatten(), y_hat.flatten())[0, 1]\n",
    "R2_tob = rho*rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = pd.DataFrame({'b_ols': theta0[:-1], 'b_tobit': b_tob, 'se': b_se_tob}, index=lblx)\n",
    "tab = pd.concat((tab,pd.DataFrame({'b_ols': theta0[-1], 'b_tobit': sig_tob, 'se': result['se'][-1]}, index=['sigma'])))\n",
    "tab = pd.concat((tab,pd.DataFrame({'b_ols': '', 'b_tobit': '', 'se': R2_tob}, index=['R2'])))\n",
    "\n",
    "tab.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your table should look something like this:\n",
    "\n",
    "Tobit Results <br>\n",
    "Dependent variable: hours <br>\n",
    "\n",
    "\n",
    "|          | b_ols   | b_tobit   |      se |\n",
    "|:---------|:--------|:----------|--------:|\n",
    "| cnst     | 1330.48 | 1272.98   | 452.357  |\n",
    "| nwifeinc | -3.45   | -8.596     |   4.427  |\n",
    "| educ     | 28.76   | 73.35     |  21.802  |\n",
    "| exper    | 65.67   | 129.9097    |  16.321  |\n",
    "| expersq  | -0.7    | -1.7967     |   0.508  |\n",
    "| age      | -30.51  | -58.85    |   7.895  |\n",
    "| kidslt6  | -442.09 | -951.048   | 113.089  |\n",
    "| kidsge6  | -32.78  | -27.986    |  38.991  |\n",
    "| sigma    | 750.18  | 1126.115   |  41.132  |\n",
    "| R2       |         |           |   0.275 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Calculate the two types of marginal effects, cf. eqs. (7) and (9), of taking an additional year of education evaluated at the mean values of the $\\mathbf{x}$'s. Remember that $\\lambda(\\mathbf{x}\\mathbf{\\beta}/\\sigma) \\equiv \\phi \\left( \\mathbf{x}\\mathbf{\\beta}/\\sigma\n",
    "\\right) / \\Phi \\left( \\mathbf{x}\\mathbf{\\beta}/\\sigma \\right)$ is called the inverse Mills ratio.\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathrm{E}\\left( y|\\mathbf{x},y>0\\right) }{\\partial x} \n",
    "&=\\beta\\Big\\{ 1 - \\lambda(\\cdot) \\big[ \n",
    "        \\mathbf{x}\\mathbf{\\beta} / \\sigma +\\lambda(\\cdot)\n",
    "    \\big] \\Big\\}. \\tag{7} \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\mathrm{E}\\left( y|\\mathbf{x}\\right) }{\\partial x}\n",
    "&= \\beta \\Phi\\left(\\frac{\\mathbf{x}\\mathbf{\\beta}}{\\sigma }\\right), \\tag{9}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "***Hints:***\n",
    "* Note that `lambda` is a keyword in Python (used when defining an anonymous function) so you cannot create a variable by that name.\n",
    "* For both marginal effects, the expression ends up being $\\boldsymbol{\\beta}$ ($K \\times 1$) times something that is scalar (when evaluated at some $\\mathbf{x} = \\mathbf{x}^0$). However, later we may want to give as an input the full `x` matrix ($N \\times K$), whereby the scalar becomes `(N,)` instead. Use `np.outer(beta, stuff)` to return an appropriate matrix in that case (it also works if `stuff` is scalar).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetahat = result['theta']\n",
    "b_tob = None # read in beta estimate \n",
    "sigma_tob = None # and sigma estimate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.mean(x, axis=0) # evaluate at the mean of x variables \n",
    "x0[4] = x0[3]*x0[3]  # Square of mean, and not mean of square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is convenient to write a function that takes a generic x as input\n",
    "# \n",
    "def mills_ratio(z):\n",
    "    return norm.pdf(z) / norm.cdf(z)\n",
    "\n",
    "def marg_effect(x, b, sigma):  \n",
    "\n",
    "    # Write up the marginal effect on E(y|x,y>0) using eq. (7). \n",
    "    # Note that the curly bracket gives you a scalar value, which you multiply on the beta vector\n",
    "    # (you can use np.outer() or regular \"*\" multiplication, but np.outer() will generalize later)\n",
    "    # Call this margeff_1\n",
    "\n",
    "    # Write up the marginal effect on E(y|x) using eq. (9). \n",
    "    # Again, you multiply the beta vector on a scalar value. \n",
    "    # Call this margeff_2\n",
    "\n",
    "    return margeff_1, margeff_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the marginal effect and print out the effect of education.\n",
    "margeff_1, margeff_2 = marg_effect(x0, b_tob, sigma_tob)\n",
    "table = [\n",
    "    ['dE(y|x,y>0)/dx', margeff_1[2]], \n",
    "    ['dE(y|x)/dx', margeff_2[2]]\n",
    "]\n",
    "print('Marginal effect of an additional year of education from tobit model')\n",
    "print(tabulate(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5:\n",
    "Calculate for all individuals the two types of marginal effects of taking an additional year of education. i) Draw a histogram of the marginal effect of education across individuals. ii) Make a scatter plot with educ along the x-axis and the marginal effect along the y-axis. Give an interpretation of your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have written the function correctly, we should be able to pass the whole x matrix thorugh the function.\n",
    "margeff_all_1, margeff_all_2 = marg_effect(x, b_tob, sigma_tob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me1 = pd.DataFrame(margeff_all_1.T, columns=lblx)\n",
    "me2 = pd.DataFrame(margeff_all_2.T, columns=lblx)\n",
    "# now you can use pandas functions like histograms on the dataframes me1 and me2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN: Plot a histogram of the marginal effect from one additional year of aducation from margeff_all_1\n",
    "# FILL IN: Plot a histogram of the marginal effect from one additional year of aducation from margeff_all_2\n",
    "\n",
    "# FILL IN: Plot a scatterplot of the marginal effect from one additional year of aducation from margeff_all_1\n",
    "# FILL IN: Plot a scatterplot of the marginal effect from one additional year of aducation from margeff_all_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covid example\n",
    "\n",
    "In the following, let's switch gears and have a look at some Covid data and estimate the Tobit model there. The overarching question is: What is the effect of temperature on disease burden? Specifically, let us focus on deaths, since it does not confound testing intensity or other measures that may be different across countries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv('covid.csv')\n",
    "dat['date'] = pd.to_datetime(dat['date'])\n",
    "\n",
    "# vaccinations are coded as missings before vaccination data collection began \n",
    "dat.people_fully_vaccinated_per_hundred = dat.people_fully_vaccinated_per_hundred.fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_fav_country = 'Denmark' # <- change this around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = (dat.country == my_fav_country) & (dat.new_deaths_per_million >= 0.0)\n",
    "plt.plot(dat[I].temperature, dat[I].new_deaths_per_million, 'o', alpha=0.2); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tobit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yvar = 'new_deaths_per_million'\n",
    "dat['const'] = 1.0 \n",
    "xvars = ['const', 'temperature', 'stringency_index', 'people_fully_vaccinated_per_hundred', 'location_workplaces', 'mobility_driving']\n",
    "I = (dat.country == 'Denmark') & (dat[yvar] >= 0.0) & (dat[xvars + [yvar]].notnull().all(axis=1))\n",
    "y = dat.loc[I, 'new_deaths_per_million'].values\n",
    "x = dat.loc[I, xvars].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta0 = tobit.starting_values(y, x)\n",
    "\n",
    "res = estimation.estimate(tobit.q, theta0, y, x, cov_type='Outer Product', method='Nelder-Mead')\n",
    "\n",
    "pd.DataFrame({'ols': theta0, 'theta': res['theta'], 't': res['t']}, index=xvars + ['sigma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E,E_pos = tobit.predict(res['theta'], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [i for i,xv in enumerate(xvars) if xv == 'temperature'][0]\n",
    "fig,ax = plt.subplots(); \n",
    "ax.plot(x[:, k], E, 'o', label='E(y|x)', alpha=0.5); \n",
    "ax.plot(x[:, k], y, '.', label='Data', alpha=0.4); \n",
    "ax.set_xlabel(xvars[k]); ax.set_ylabel(yvar); \n",
    "ax.legend(); "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
