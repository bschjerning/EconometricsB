{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  Project 2: Binary response models for panel data: Monte Carlo Evidence\n",
    "\n",
    "### Due: Wednesday March 24th at 22:00\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A dynamic binary response model for panel data\n",
    "The overall purpose of this project is to use Monte Carlo simulation to investigate the properties of estimators for binary response models for panel data. \n",
    "\n",
    "For concreteness, consider the dynamic panel data model specified below\n",
    "\n",
    "\\begin{eqnarray} \n",
    "y_{it}&=&\\mathbb{1}(\\delta z_{it}  + \\rho y_{it-1} + c_i +e_{it}>0) \\\\\n",
    "y_{i0}&=&\\mathbb{1}(\\eta_i>0) \\\\\n",
    "c_i   &=& \\phi_0 + \\phi_{y0} y_{i0} + a_i\\\\\n",
    "a_i &\\sim&  iidN(0, \\sigma_a^2)\\\\\n",
    "e_{it} &\\sim& iidN(0, 1) \\\\\n",
    "\\eta_{i} &\\sim& iidN(0, 1) \n",
    "\\end{eqnarray}\n",
    "\n",
    "where the scalar random variable $z_{it}$ is assumed to be iid standard normally distributed. Depending on the parameters, this model can be either dynamic (if $\\rho \\ne 0$) or static (if $\\rho = 0$) and may or may not contain unobserved effects depending on the parameters that determine $c_i$. \n",
    "\n",
    "We are specifically interested in estimating the effect of $z_{it}$ and $y_{it-1}$ on $P(y_{it}=1|z_{it}, y_{it-1}, c_i)$, that is the effect of changing $z_{it}$ or $y_{it-1}$ holding constant other variables including $c_i$. \n",
    "\n",
    "## 2. Research questions\n",
    "During the lectures 13 and 14 on \"Binary response models for panel data\" we considered a battery of different models and estimators. Each method may or may not be appropriate depending on the nature of the data and what the object of interest is. Sometimes we are satisfied with estimating the direction of an effect that may be determined by the sign of the coefficient to single explanatory variable. Sometimes the interest is in the average partial effect (APE) and other times we need to make inference about the whole distribution of choice probabilities and corresponding partial effects. \n",
    "\n",
    "Each estimator are derived under different assumptions, and will be appropriate in different context and have different asymptotic properties. This may for example depend on \n",
    "1. whether there are **unobserved effects** in the data and whether they are **correlated with explanatory variables**\n",
    "1. whether the model is **static** or **dynamic**, for example because it contains a lagged dependent variable \n",
    "1. whether you consider a **pooled analysis** or specify a model for **the conditional distribution for the entire sequence** of observed binary outcomes \n",
    "1. how modest your ambitions are in terms of the **object of interest**\n",
    "\n",
    "This motivates a menu research questions: \n",
    "1. Is it possible to identify the parameter of interest? \n",
    "1. What is the appropriate estimator? \n",
    "1. Is the estimator $\\sqrt{N}$-consistent and asymptotic normal? \n",
    "1. Is it unbiased?\n",
    "1. Is it efficient?\n",
    "1. Are asymptotic results a good approximation for the sample size under consideration? \n",
    "1. Are the usual standard errors and tests-statistics valid for inference, or do I need to compute robust standard errors? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The assignment\n",
    "To analyze the questions above, you are asked to perform a series of Monte Carlo experiments where you change the sampling scheme using the model specified above and compare the performance of different estimators derived from different models such as: \n",
    "\n",
    "1. **Linear probability models with unobserved effects** estimated using least squares methods such as for example Pooled OLS, Fixed Effects, First Differencing IV methods etc. \n",
    "1. **Pooled index models** estimated using partial MLE, such as Pooled Probit or Pooled Logit \n",
    "1. **Index models with unobserved effects under strict exogeneity** such as the Random effects Probit, Chamberlain's Correlated Random effects Probit or Fixed Effects Logit. \n",
    "1. **Dynamic unobserved effects models** such as the Dynamic version of the Correlated Random effects Probit \n",
    "\n",
    "As a testbed for different estimators we use the dynamic binary probit model with unobserved effects described in Section 1. Use the model to generate data sets for different values of parameters and sample size, and investigate the properties of different estimators. \n",
    "\n",
    "**Your analysis does not have to be exhaustive**, but you need to consider *at least one method from at least three out of the four classes mentioned above*. Divide your analysis into static models and dynamic models. In the latter case, special focus in on the causal effect of the lagged dependent variable (state dependence). Here you need to discriminate between true and *spurious state dependence* and analyze the importance of accounting for unobserved heterogeneity and the initial conditions problem. \n",
    "\n",
    "The same rule applies regarding your analysis of the properties of the estimators you apply. Think of the list of research questions above as a menu of opportunities. In the next section I give more examples of specific questions to analyze. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Some advice on Monte Carlo: Analyzing properties of estimators\n",
    "I recommend you start simple. Generate data from a model where you know you should be able to recover the underlying parameters by estimating a well specified model that is consistent with how you generated the data. Then you can set up more sophisticated experiments such as the ones we discussed during lectures: \n",
    "\n",
    "#### Example experiments - static models\n",
    "1. No heterogeneity \n",
    "    - does LPM give a good approximation of APE\n",
    "    - does pooled probit estimate true parameters\n",
    "    \n",
    "1. Neglected heterogeneity - Pooled probit or LPM\n",
    "   - does pooled probit estimate true parameters?\n",
    "   - does pooled OLS and probit still estimate APE?\n",
    "\n",
    "1. Can RE-Probit estimate account for heterogeneity and uncover true parameters\n",
    "\n",
    "#### Example experiments - dynamic models   \n",
    "1. Neglecting heterogeneity and initial conditions\n",
    "   - does pooled OLS and probit consistently estimate APE of lagged y (state dependence)?\n",
    "   - what about other parameters?\n",
    "1. Accounting for heterogeneity and initial conditions \n",
    "    - is LPM-FE valid for dynamic models?\n",
    "    - can RE probit estimate APE of lagged y (state dependence)?\n",
    "    - what if explanatory variables are correlated with c_i?\n",
    "\n",
    "In the simulation exercise in the lectures on binary response for panel data, we essentially did Monte Carlo using only a single Monte Carlo sample. To appropriately analyze the distribution of an estimator, test-statistic, etc. you need to generate many samples by repeatedly simulating data and estimating the parameter of interest. Using this information, we can for example learn about the distribution of an estimator. As an example, the notebook [clogit_simulations.ipynb](https://github.com/bschjerning/metrics2021/blob/main/14_multinomial_response/clogit_simulations.ipynb) provides a simple example in the context of the Condtional Logit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 More resources\n",
    "The most relevant sections is Wooldridge's textbook are (in order of priority)\n",
    "- Section 15.8 on Binary Response models for Panel data\n",
    "- Section 12.8.1 on Monte Carlo Simulation \n",
    "- Section 13.8 and 13.9 on Partial/Pooled MLE and likelihood based panel data methods with unobserved effects. \n",
    "- Sections 12.1-12.3, and 12.5.1 on the properties of M-Estimators\n",
    "\n",
    "Most of of the relevant estimation methods and econometric models are reviewed in the lectures 13 and 14 on \"Binary response models for panel data\" and implemented in the notebook [binary_choice_panel.ipynb](https://github.com/bschjerning/metrics2021/blob/main/12_binary_response_panel/binary_choice_panel.ipynb). Here you will also find demonstrations of the code that implements a selection of panel data methods for binary response. For convenience, I located the current notebook in the same directory [12_binary_response_panel](https://github.com/bschjerning/metrics2021/tree/main/12_binary_response_panel), so that you can easily access all resources. \n",
    "\n",
    "For Monte Carlo, you may get some inspiration from the first exercise set, where we do a simple Monte Carlo Experiment for the linear model. You may also want to look a the last lecture on the simulation and maximum likelihood estimation of the conditional logit model. As mentioned above, The notebook [clogit_simulations.ipynb](https://github.com/bschjerning/metrics2021/blob/main/14_multinomial_response/clogit_simulations.ipynb) briefly illustrates how properties the maximum likelihood estimator for conditional logit can be analyzed though a simple Monte Carlo experiment. \n",
    "\n",
    "You may also need the code used during the exercise classes, or even take the challenge of writing code for estimators I have not implemented, such as the Fixed Effects Logit model. You are encouraged to use all resources available and modify it so it fits your application. If you take up this challenge. Start simple. Consider first the model for only two periods, and move on from there.\n",
    "\n",
    "It may also be that you want to modify the sampling scheme. For example, in the model above (and associated simulation code) $z_{it}$ is assumed to be uncorrelated with $c_i$. So if your are interested in analyzing the consequences of correlated unobserved effects, you are welcome to extend the simulation framework to for example allow for correlation between unobserved effects and the explanatory variables.  \n",
    "\n",
    "## 6. Getting started\n",
    "To make sure we are all on the same page, lets do a few initial steps here \n",
    "\n",
    "### Initial setup\n",
    "Before we begin, lets read in some modules used though-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import linalg as la\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Routine for simulation of model\n",
    "The model outlined above is implemented in the function ''simulate'' in indexmodels.py \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>group</th>\n",
       "      <th>period</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>y0</th>\n",
       "      <th>const</th>\n",
       "      <th>l1.y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.722200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.612669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.075337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.796417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>999.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.283865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>999.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531214</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>999.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.910966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>999.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.841532</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>999.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.125048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       group  period    y         z   y0  const  l1.y\n",
       "1        0.0     1.0  0.0  0.722200  0.0    1.0   0.0\n",
       "2        0.0     2.0  0.0  0.088782  0.0    1.0   0.0\n",
       "3        0.0     3.0  0.0 -0.612669  0.0    1.0   0.0\n",
       "4        0.0     4.0  0.0  1.075337  0.0    1.0   0.0\n",
       "5        0.0     5.0  0.0  0.796417  0.0    1.0   0.0\n",
       "...      ...     ...  ...       ...  ...    ...   ...\n",
       "10995  999.0     6.0  0.0 -2.283865  0.0    1.0   0.0\n",
       "10996  999.0     7.0  1.0  0.531214  0.0    1.0   0.0\n",
       "10997  999.0     8.0  1.0  1.910966  0.0    1.0   1.0\n",
       "10998  999.0     9.0  0.0 -0.841532  0.0    1.0   1.0\n",
       "10999  999.0    10.0  1.0 -0.125048  0.0    1.0   0.0\n",
       "\n",
       "[10000 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate data from dynamic model\n",
    "from indexmodels import *\n",
    "df_sim=simulate(n=1000, nT=10, model='probit', rho=.1, delta=1, phi_0=0, phi_y0=0, sigma_a=1)\n",
    "df_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Routines for estimators and estimation methods\n",
    "The file [indexmodels.py](https://github.com/bschjerning/metrics2021/blob/main/12_binary_response_panel/indexmodels.py) also contain implementations of pooled probit/logit and random effects probit/logit models. It relies on [mestim.py](https://github.com/bschjerning/metrics2021/blob/main/12_binary_response_panel/mestim.py) that contains a routine for implementation of the general class of M-estimators known from Chapter 12 - including MLE (if you specify the objective function appropriately).  \n",
    "The file [linearpaneldata.py](https://github.com/bschjerning/metrics2021/blob/main/12_binary_response_panel/linearpaneldata.py) includes simple routines for pooled ols and fixed effects regressions. Here you may want to subplement with the code from exercise classes on static and dynamic linear panel data models.  \n",
    "\n",
    "As a starting point, we could for example use these routines to simulate data from a static unobserved effects model with one strictly exogneous explanatory variable, $z_{it}$, and estimate the effect of $z_{it}$ using a variety of methods. You may get something like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Specification: Pooled OLS Panel Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.2231      0.0039     56.7381\n",
      "const           0.5098      0.0084     60.4079\n",
      "# of groups:       1000\n",
      "# of observations: 10000 \n",
      "\n",
      "\n",
      "Specification: Linear Fixed Effects Regression\n",
      "Dep. var. : y \n",
      "\n",
      "parnames         b_hat          se    t-values\n",
      "----------  ----------  ----------  ----------\n",
      "z               0.2234      0.0039     57.6217\n",
      "# of groups:       1000\n",
      "# of observations: 10000 \n",
      "\n",
      "Pooled probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.67689     0.01704    39.73091    -0.00000     0.22341\n",
      "const           0.03129     0.02553     1.22556    -0.00000     0.01033\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -5810.164383287176 \n",
      "\n",
      "Iteration info: 4 iterations, 5 evaluations of objective, and 5 evaluations of gradients\n",
      "Elapsed time: 0.3422 seconds\n",
      "\n",
      "Random effects probit\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac         APE\n",
      "----------  -----------  ----------  ----------  ----------  ----------\n",
      "z               0.97204     0.02276    42.70713    -0.00000     0.22381\n",
      "const           0.04429     0.03650     1.21353     0.00000     0.01020\n",
      "sigma_a         1.02538     0.03430    29.89545     0.00000     0.23609\n",
      "\n",
      "# of groups:      : 1000\n",
      "# of observations : 10000\n",
      "# log-likelihood. : -4923.168117065761 \n",
      "\n",
      "Iteration info: 7 iterations, 8 evaluations of objective, and 8 evaluations of gradients\n",
      "Elapsed time: 1.4264 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import linearpaneldata as lpd   # simple routines to do linear FE and Pooled OLS regressions\n",
    "from indexmodels import *       # objective functions etc. for estimation of panel data binary response models\n",
    "import mestim as M              # routines for M-estimation given general sample objective functions\n",
    "\n",
    "# Simulate data\n",
    "simulate(n=1000, nT=10, delta=1, rho=0, psi=0, phi_0=0,  phi_y0=0, sigma_a=2, \n",
    "         model='probit', rng=random.default_rng(seed=43))\n",
    "\n",
    "# Estimate models\n",
    "lpm_ols=lpd.estim(df_sim, 'y', xvar=['z', 'const'], groupvar='group', method='pols', cov_type='robust')\n",
    "lpm_fe=lpd.estim(df_sim, 'y',  xvar=['z'], groupvar='group', method='fe', cov_type='robust')\n",
    "res_pp=pooled(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='sandwich')\n",
    "res_rep=rand_effect(df_sim, 'y', xvar =['z', 'const'] , groupvar='group', model='probit', cov_type='Binv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. General advice for academic writing and scientific approach \n",
    "***(same hints as for last project)***\n",
    "1. Remember to properly define all variables and symbols employed and distinguish between them. For example, you should distinguish between the true parameter and an estimate thereof. Strive to employ the notation used in the course/textbook. Make use of boldface and capitalization to avoid confusing scalars, vectors and matrices (do as I say, not as I do). Specify dimensions whenever confusion may arise.\n",
    "\n",
    "2. When using an estimation procedure, carefully discuss the assumptions required to derive the estimator and establish properties thereof, and assess whether these assumptions are likely to be satisfied in the current empirical setting. If not, what are the consequences for the estimator in question (and your results)?\n",
    "\n",
    "3. If you come up with several model specifications and associated estimates, discuss which one seems the most appropriate and justify your decision (e.g., based on formal testing).\n",
    "\n",
    "4. Be precise about the statistical tests you use for testing various hypotheses. Explain which null hypothesis you are testing and the alternative you are testing against, how the test statistic is constructed, the decision rule you employ, and the conclusion you reach. If a variance (matrix) has been estimated, discuss the assumptions invoked for consistency. If several choices are possible, justify your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Formal Requirements\n",
    "\n",
    "- You must hand in a report that presents the econometrics model, outlines the modeling process (e.g., the approach taken, the alternative models you have considered, etc.), presents your preferred estimation results and results of formal statistical tests (including interpretation and statements on economic and statistical significance), and discusses the potential weaknesses of the model, data and approach.\n",
    "\n",
    "- The report must be written in English and uploaded to Peergrade via Absalon as a single PDF file.\n",
    "\n",
    "- The report must be at most 12,000 characters long (including spaces) plus at most two pages of output in the form of (properly formatted and labelled) tables or graphs.\n",
    "\n",
    "- 12,000 characters correspond to five normal pages of text, a normal page of text being defined as having fontsize = 12p, line spacing = 1.5, and 2.5 cm margins.\n",
    "\n",
    "- The (free) document processor LyX allows you to count characters with/without blanks (via Tools $\\to$ Statistics). You may import a (plain) LaTeX file into LyX (via File $\\to$ Import). Alternatively, pick a representative fraction (e.g., a tenth) of your report, count characters manually, and scale the result to see whether you are in the ballpark.\n",
    "\n",
    "- You are allowed (and strongly encouraged) to work in groups of up to three people. List all group members on the front page of your report.\n",
    "\n",
    "- The assessment criteria are given on the course website in Absalon."
   ]
  }
 ],
 "metadata": {
  "date": 1602643870.398518,
  "filename": "38_optimization.rst",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "title": "Foundations of Computational Economics #38"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
