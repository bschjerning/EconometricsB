{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Introduction to Multinomial Responses\n",
    "\n",
    "### Econometrics B (ØkB)\n",
    "\n",
    "**Bertel Schjerning**  \n",
    "Department of Economics, University of Copenhagen  \n",
    "\n",
    "### Readings:  \n",
    "- [Train, Ch. 3 Logit](https://eml.berkeley.edu/books/choice2nd/Ch03_p34-75.pdf)\n",
    "- Wooldridge ch. 16 (suplementary)\n",
    "\n",
    "### References:  \n",
    "- Wooldridge, J.M. (2010). *Econometric Analysis of Cross Section and Panel Data*, 2nd ed., MIT Press, Ch. 16.  \n",
    "- Train, K. (2009). *Discrete Choice Methods with Simulation*, 2nd ed., Cambridge University Press.\n",
    "[Download 1st ed. of book](https://eml.berkeley.edu/books/choice2.html)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why Discrete Choice Models?\n",
    "\n",
    "- Many economic decisions involve choosing **one among many alternatives**:  \n",
    "  - Which mode of transport? (**Car, bus, train**)  \n",
    "  - Which product to buy? (**iPhone, Samsung, Google Pixel**)  \n",
    "  - Which university program to apply for? (**Ranked application system in Denmark**)  \n",
    "\n",
    "- **Choices come from a finite set**, requiring models that capture **utility differences across alternatives**.  \n",
    "\n",
    "### Types of Discrete Responses and Suitable Models  \n",
    "\n",
    "- **Binary Choice** (Work or not work) → **Binary Logit / Probit**  \n",
    "- **Unordered Choice** (Transportation mode, product purchase, educational choice) <br>→ **Multinomial Logit, Nested Logit, Mixed Logit**  \n",
    "- **Ordered Choice** (Lecturer rating: Awful, Acceptable, Awesome) → **Ordered Logit / Ordered Probit**  \n",
    "- **Ranked Choice** (University admissions, job applications) → **Exploded Logit, Rank-Ordered Logit**  \n",
    "- **Count Data** (Homepage visits, COVID cases) → **Poisson, Negative Binomial Regression**  \n",
    "\n",
    "We focus on **unordered choices**, where consumers select the option with the highest utility.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Today: Unordered Multinomial Responses  \n",
    "\n",
    "- **Individuals $i$ choose among $J$ mutually exclusive alternatives**  \n",
    "  - **Education** (MSc, BSc, High School)  \n",
    "  - **Transport** (Car, Bus, Train)  \n",
    "  - **Car Brand** (Ford, BMW, Tesla)  \n",
    "\n",
    "- **Deja vi from Econometrics A**: Logit demand model for **market shares in car demand** (OLS/IV/GMM)  \n",
    "- **Now**: Model **individual choices** and derive choice probabilities (estimate with MLE) \n",
    "- **Later**: Return to **market shares** formulation aggreating individual choices (estimate with GMM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extending binary choice models to **multiple alternatives**.\n",
    "\n",
    "- Interested in modeling the conditional choice probability (CCP) for a finite number of alternatives, $j\\in\\{0,\\ldots,J\\}$\n",
    "\n",
    "$$p_j(x)=P(y=j|x) \\in (0,1)$$ \n",
    "\n",
    "\n",
    "- Because alternatives are *mutually exclusive*, CCPs sum to 1 \n",
    "\n",
    "$$\\sum_{j\\in\\{0,\\ldots,J\\}} p_j(x)=1$$\n",
    "\n",
    "- So $p_0(x)=P(y=0|x)$ is determined once we know $p_j(x)$ for $j\\in\\{1,\\ldots,J\\}$\n",
    "\n",
    "$$p_0(x)=1-\\sum_{j=1}^J p_j(x)$$\n",
    "\n",
    "- **How do we model $p_j(x)$?**  \n",
    "  - Need a **structural model**  \n",
    "  - This leads us to the **Random Utility Model (RUM)**  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Random Utility Model (RUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Random Utility Model (RUM)\n",
    "\n",
    "**Decision rule**  \n",
    "$$ y_i = \\arg \\max_{j\\in\\{0,\\ldots,J\\}} u_{ij}, \\quad u_{ij} = v_{ij} + \\varepsilon_{ij} $$  \n",
    "\n",
    "- **Setup**:  \n",
    "  - $i=1,\\ldots,N$ (individuals), $j=0,\\ldots,J$ (alternatives)  \n",
    "  - $y_i$ = chosen alternative  \n",
    "  - $u_{ij}$ = total utility  \n",
    "  - $v_{ij}$ = deterministic utility  \n",
    "  - $\\varepsilon_{ij}$ = stochastic term (observed by decision maker, not econometrician)  \n",
    "\n",
    "**Key Models**  \n",
    "- **Logit models**: $\\varepsilon_{ij} \\sim$ i.i.d. extreme value  \n",
    "- **Conditional Logit**: $v_{ij} = x_{ij} \\beta$  \n",
    "- **Multinomial Logit**: $v_{ij} = x_i \\beta_j$  \n",
    "- **Combined Logit**: $v_{ij} = z_{ij}' \\beta + w_i \\gamma_j$  \n",
    "\n",
    "**Implications**  \n",
    "- Logit assumes **Independence of Irrelevant Alternatives (IIA)**  \n",
    "- **Are these assumptions realistic?**  \n",
    "- **How can they be relaxed? (Nested Logit, Mixed Logit, Random Coefficients Logit)**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More on Utility  \n",
    "\n",
    "The observed component of utility, $v_{ij} = v(w_i, z_{ij})$, **does not have to be linear**.  \n",
    "\n",
    "### Examples:  \n",
    "\n",
    "- **Indirect Utility in Static Optimization**  \n",
    "  - When utility depends on another choice variable $c$:  \n",
    "    $$ v_{ij} = \\max_c \\tilde{v}_{ij}(c) $$  \n",
    "\n",
    "- **Choice-Specific Value Function in Dynamic Models**  \n",
    "  - When choices impact future states:  \n",
    "    $$ v(x, j) = \\tilde{u}(x, j) + \\rho \\int V(x') p(x' | x, j) dx' $$  \n",
    "  - With **expected value function**:  \n",
    "    $$ V(x) = \\int_\\varepsilon \\max_j (v(x, j) + \\varepsilon_j) d\\varepsilon = \\log \\sum_j \\exp(v(x, j)) $$  \n",
    "  - Where:  \n",
    "    - $\\rho$ = discount factor  \n",
    "    - $p(x' | x, j)$ = transition density of state variables  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choice probabilities\n",
    "- From the **random utility model**:  \n",
    "$$y_i = \\arg \\max_{j\\in\\{0,\\ldots,J\\}} u_{ij}\n",
    "\\qquad\\qquad\n",
    "u_{ij} = v_{ij} + \\varepsilon_{ij}$$\n",
    "- Probability of choosing $j$:  \n",
    "$$\\begin{array}{lcl}\n",
    "p_{ij} \\equiv P(y_i = j) \n",
    "&=& P(u_{ij} > u_{ik} \\quad\\forall k\\neq j) \\\\[1ex]\n",
    "&=& P(v_{ij} + \\varepsilon_{ij} > v_{ik} + \\varepsilon_{ik} \\quad\\forall k\\neq j) \\\\[1ex]\n",
    "&=& P(\\varepsilon_{ik}-\\varepsilon_{ij} < v_{ij}-v_{ik} \\quad\\forall k\\neq j) \\\\[1ex]\n",
    "\\end{array}$$\n",
    "\n",
    "- The expression for $p_{ij}$ **depends on the distribution** of $\\varepsilon_{ij}$ \n",
    "    - How to choose the distribution of $\\varepsilon_{ij}$? \n",
    "    - What will be the implied distribution of $\\varepsilon_{ik}-\\varepsilon_{ij}$?\n",
    "    - Popular choice for $\\varepsilon_{ij}$ is the *Type 1 Extreme Value (Gumbel) Distribution*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Type 1 Extreme Value (Gumbel) Distribution (Location-Scale Form)\n",
    "For location $\\mu$ and scale $\\sigma$:  \n",
    "$$\n",
    "F(\\varepsilon) = \\exp\\left\\{-\\exp\\left(-\\frac{\\varepsilon - \\mu}{\\sigma}\\right)\\right\\}, \\quad\n",
    "f(\\varepsilon) = \\frac{1}{\\sigma} \\exp\\left\\{-\\frac{\\varepsilon - \\mu}{\\sigma} - \\exp\\left(-\\frac{\\varepsilon - \\mu}{\\sigma}\\right)\\right\\}\n",
    "$$  \n",
    "- **Limit distribution** for max of $N$ i.i.d. random variables as $N \\to \\infty$.  \n",
    "- **Mean:** $\\mu + \\gamma\\sigma$, where $\\gamma \\approx 0.577$ (Euler-Mascheroni constant).  \n",
    "- **Variance:** $\\frac{\\pi^2}{6} \\sigma^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "μ, σ = 0, 1  # Location and scale \n",
    "# μ, σ  = -0.5772 * (6 / np.pi**2)**0.5, (6 / np.pi**2)**0.5 # uncomment to set E(ε)=0, var(ε)=1\n",
    "ε = np.linspace(-5, 5, 100)\n",
    "F = lambda ε: np.exp(-np.exp(-(ε - μ) / σ))\n",
    "f = lambda ε: (1 / σ) * np.exp(-(ε - μ) / σ - np.exp(-(ε - μ) / σ))\n",
    "Φ, ϕ = norm.cdf, norm.pdf  \n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "ax1.plot(ε, F(ε), 'r--', ε, Φ(ε))\n",
    "ax1.legend([r'Extreme Value CDF, $F(\\varepsilon)$', r'Normal CDF, $\\Phi(\\varepsilon)$'])\n",
    "ax2.plot(ε, f(ε), 'r--', ε, ϕ(ε))\n",
    "ax2.legend([r'Extreme Value PDF, $f(\\varepsilon)$', r'Normal PDF, $\\phi(\\varepsilon)$'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why the Type 1 Extreme Value (EV) Distribution?  \n",
    "\n",
    "<img src=\"img/evdist.png\" width=\"900\" height=\"400\">\n",
    "\n",
    "- The **EV distribution is right-skewed**, but only **error differences** in RUM matter:  \n",
    "  $$ p_{ij} = P(\\varepsilon_{ik} - \\varepsilon_{ij} < v_{ij} - v_{ik}, \\forall k \\neq j) $$  \n",
    "\n",
    "- If $\\varepsilon_j, \\varepsilon_k \\sim$ i.i.d. EV, then  \n",
    "  $$ \\varepsilon_j - \\varepsilon_k \\sim \\text{Logistic} $$  \n",
    "  - This **logistic difference property** gives **closed-form logit probabilities** in the binary case.  \n",
    "  - It also **extends to the multinomial case**, allowing us to derive **multinomial logit probabilities**:  \n",
    "    $$ p_{ij} = \\frac{\\exp(v_{ij})}{\\sum_{m=0}^{J} \\exp(v_{im})} $$  \n",
    "\n",
    "- The EV distribution is **max stable**:  \n",
    "  - The **maximum** of $n$ i.i.d. EV-distributed variables remains EV-distributed.  \n",
    "  - A **generalization leads to nested logit models**.  \n",
    "  - **Contrast with normal distributions**: sums of normals remain normal.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Choice Probabilities  \n",
    "\n",
    "For additive random utility models:  \n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "p_{ij}  \n",
    "&=& P\\left(u_{ij} > u_{im}, \\forall m \\neq j \\right) \\\\\n",
    "&=& P\\left(v_{ij} + \\varepsilon _{ij} > v_{im} + \\varepsilon _{im}, \\forall m \\neq j \\right) \\\\\n",
    "&=& \\int_{\\varepsilon_{i0},\\dots,\\varepsilon_{iJ}} \\mathbb{1} \\left( \\varepsilon_{im} - \\varepsilon_{ij} < v_{ij} - v_{im}, \\forall m \\neq j \\right) \\\\\n",
    "&& \\quad f\\left( \\varepsilon_{i0},\\dots,\\varepsilon_{iJ} \\right) d\\varepsilon_{i0} \\dots d\\varepsilon_{iJ} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- **Non-logit models require solving high-dimensional integrals** \n",
    "- **Error differences reduce dimension to $J$**, but still costly when $J$ is large  \n",
    "- **Panel data worsens the problem**: If $\\varepsilon_{ij}$ is a $T$-vector, dimension of integration scales with $J \\times T$  \n",
    "- **Logit avoids integration** and give **closed-form choice probabilities**, making estimation computationally feasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logit: \"Closed Form\" Choice Probabilities  \n",
    "\n",
    "**Start with additive RUM**:  \n",
    "  $$ p_{ij} = P(v_{ij} + \\varepsilon_{ij} > v_{im} + \\varepsilon_{im}, \\forall m \\neq j) $$  \n",
    "\n",
    "**Condition on $\\varepsilon_{ij}$**:  \n",
    "  $$ p_{ij} | \\varepsilon_{ij} = P(\\varepsilon_{im} < v_{ij} - v_{im} + \\varepsilon_{ij}, \\forall m \\neq j \\mid \\varepsilon_{ij}) $$  \n",
    "\n",
    "**Now assume $\\varepsilon_{im} \\sim$ i.i.d. EV:** <br>\n",
    "Because EV-distributed errors are **independent**, the probability of all inequalities holding factorizes into product of probabilities\n",
    "\n",
    "  $$ p_{ij} | \\varepsilon_{ij} = \\prod_{m \\neq j} e^{-e^{-(\\varepsilon_{ij} + v_{ij} - v_{im})}} $$  \n",
    "\n",
    "**Conditioning on $\\varepsilon_{ij}$ reduces the $(J+1)$-dimensional integral to a single integral**:  \n",
    "  $$ p_{ij} = \\int_{\\varepsilon_{ij}} \\left( \\prod_{m \\neq j} e^{-e^{-(\\varepsilon_{ij} + v_{ij} - v_{im})}} \\right) e^{-\\varepsilon_{ij} - e^{-\\varepsilon_{ij}}} d\\varepsilon_{ij} $$  \n",
    "\n",
    "**This integral has a closed-form solution, leading to the well-known logit formula**:  \n",
    "  $$ p_{ij} = \\frac{\\exp(v_{ij})}{\\sum_{m=0}^{J} \\exp(v_{im})} $$  \n",
    "\n",
    "(See next slide for the full derivation of the integral.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Solving the Integral\n",
    "Noting that $v_{ij} - v_{ij} = 0$ and collecting terms, we get:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lcl}\n",
    "p_{ij} &=& \\int_{-\\infty}^{\\infty} \\left(\\prod_{m} e^{-e^{-(\\varepsilon_{ij} + v_{ij} - v_{im})}}\\right) e^{-\\varepsilon_{ij}} d\\varepsilon_{ij} \\\\[1em]\n",
    "&=& \\int_{-\\infty}^{\\infty} \\exp\\left(-\\sum_{m} \\exp(-(\\varepsilon_{ij} + v_{ij} - v_{im}))\\right) e^{-\\varepsilon_{ij}} d\\varepsilon_{ij} \\\\[1em]\n",
    "&=& \\int_{-\\infty}^{\\infty} \\exp\\left(-e^{-\\varepsilon_{ij}} \\sum_{m} \\exp(-(v_{ij} - v_{im}))\\right) e^{-\\varepsilon_{ij}} d\\varepsilon_{ij}.\n",
    "\\end{array}\n",
    "$$  \n",
    "\n",
    "Using the substitution $t = e^{-\\varepsilon_{ij}}$, so that $dt = -e^{-\\varepsilon_{ij}} d\\varepsilon_{ij}$, we obtain:  \n",
    "\n",
    "$$\n",
    "p_{ij} = \\int_{0}^{\\infty} \\exp\\left(-t \\sum_{m} \\exp(-(v_{ij} - v_{im}))\\right) dt.\n",
    "$$  \n",
    "\n",
    "Evaluating the integral:\n",
    "\n",
    "$$\n",
    "p_{ij} = \\left[ \\frac{\\exp(-t \\sum_{m} \\exp(-(v_{ij} - v_{im})))}{-\\sum_{m} \\exp(-(v_{ij} - v_{im}))} \\right]_{0}^{\\infty}.\n",
    "$$  \n",
    "\n",
    "Substituting limits:\n",
    "\n",
    "$$\n",
    "p_{ij} = \\frac{1}{\\sum_{m=0}^{J} \\exp(v_{im} - v_{ij})} = \\frac{\\exp(v_{ij})}{\\sum_{m=0}^{J} \\exp(v_{im})}.\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Identification in Random Utility Models**  \n",
    "\n",
    "**Affine transformations of utility do not affect choices**:  \n",
    "  $$ u_{ij}^* = a_i + b_i u_{ij}, \\quad b_i > 0 $$  \n",
    "The transformation can be **individual-specific** ($a_i$, $b_i$ can vary across $i$) but **independent of $j$**.  \n",
    "\n",
    "**Decision rule remains unchanged** under transformation:  \n",
    "\\begin{align}\n",
    " p_{ij} &=P(a_i + b_i u_{ij} > a_i + b_i u_{im}, \\forall m \\neq j)  \n",
    "  \\\\ &=P(b_i u_{ij} > b_i u_{im}, \\forall m \\neq j)   \n",
    "  \\\\ &=P(u_{ij} > u_{im}, \\forall m \\neq j)   \n",
    "\\end{align}\n",
    "  - The constant shift $a_i$ **cancels out** from both sides of the inequalities.  \n",
    "  - The positive scale factor $b_i$ **does not affect the inequalities**.\n",
    "  - Models are **observably equivalent** for any $a_i$ and any positive scaling factor $b_i$.\n",
    "  \n",
    "### Implication:  \n",
    "- **Only differences in utility matter** \n",
    "- **Utility scale is arbitrary**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Normalization needed for identification\n",
    "- **Level normalization:** Fix a reference alternative (e.g., set $u_{i0} = 0$).  \n",
    "- **Scale normalization:** Fix the variance of $\\varepsilon_{ij}$ (e.g., $\\sigma = 1$) or normalize a coefficient.  \n",
    "\n",
    "*These normalizations are required for all discrete choice models, not just logit.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Identification example: \n",
    "Start with the linear utility specification:\n",
    "\n",
    "$$u_{ij} = \\color{red}{\\alpha_i} + \\delta_j + x_{ij} \\beta_i + z_i \\gamma_j + \\color{red}{w_i \\phi} + \\sigma \\varepsilon_{ij}$$\n",
    "\n",
    "Compute utility differences relative to reference alternative $j=0$\n",
    "\n",
    "$$\n",
    "u_{ij} - u_{i0} = \\color{red}{(\\delta_j - \\delta_0)} + (x_{ij} - x_{i0}) \\beta_i + z_i \\color{red}{(\\gamma_j - \\gamma_0)}  + \\color{red}{\\sigma} (\\varepsilon_{ij} - \\varepsilon_{i0})\n",
    "$$\n",
    "\n",
    "- **Only differences in utility matter:** \n",
    "    - Any component that does not vary over alternatives cancels out ( intercept $\\alpha_i$ and $w_i\\phi$) \n",
    "    - Alternative-specific intercepts ($\\delta_j$) is only be identified relative to a baseline ($\\delta_0$).\n",
    "    - Alternative-specific coefficents to $z_i$ ($\\gamma_j$) is only be identified relative to a baseline ($\\gamma_0$).\n",
    "    - Individual-specific variables ($w_i$) must interact with alternative-specific effects ($\\gamma_j$), or they drop out.\n",
    "\n",
    "- **Scale of utility is arbitrary:**\n",
    "    - The scale of $\\varepsilon_{ij}$ is arbitrary → We must impose scale normalization (e.g., $\\sigma=1$ or fix a coefficient).\n",
    "    - Fixing $\\sigma=1$ implies that parameters are measured relative to $\\sigma$, e.g. ${(\\delta_j - \\delta_0)}/\\sigma$\n",
    "    \n",
    "✅ **Key Takeaway:** **Both level and scale normalizations are essential for identification and affect interpretation of parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Identification in Conditional vs. Multinomial Logit**  \n",
    "\n",
    "### **Conditional Logit (CL)**  \n",
    "$$ u_{ij} = x_{ij} \\beta + \\sigma \\varepsilon_{ij} $$\n",
    "- $x_{ij}$: **$1 \\times K$ vector** of characteristics of **alternative $j$** for individual $i$.  \n",
    "- **Example (Education choice)**:\n",
    "  $$ x_{ij} = (\\texttt{Const}_{j}, \\texttt{Costs}_{ij}, \\texttt{StudyTime}_{ij}, \\texttt{ExpectedWage}_{ij}, \\dots) $$  \n",
    "- **Identification**: No choice-invariant intercepts, fixed scale (e.g., $\\sigma=1$).  \n",
    "- **Interpretation of $\\beta_k$**: Marginal utility of $x_{ij,k}$.  \n",
    "\n",
    "### **Multinomial Logit (MNL)**  \n",
    "$$ u_{ij} = x_i \\beta_j + \\sigma \\varepsilon_{ij} $$\n",
    "- $x_i$: **$1 \\times K$ vector** of characteristics of **individual $i$** (same across alternatives).  \n",
    "- **Example (Education choice)**:  \n",
    "  $$ x_i = (\\texttt{Age}_i, \\texttt{ParentsEduc}_i, \\dots) $$  \n",
    "- **Identification**: Requires a **baseline alternative** (e.g., $\\beta_0 = 0$), fixed scale (e.g., $\\sigma=1$).  \n",
    "- **Interpretation of $\\beta_{jk}$**: Effect of individual characteristic $x_i^k$ on utility of alternative $j$ (relative to baseline $j=0$).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Identification: Conditional logit\n",
    "- **Location problem:**\n",
    "\n",
    "$$\\begin{array}{lcl}\n",
    "p_{ij}\n",
    "&=&\\dfrac{\\exp\\{{\\color{red}\\beta_0} + x_{ij}\\beta\\}}\n",
    "         {\\sum_{k=0}^J\\exp\\{{\\color{red}\\beta_0} + x_{ik}\\beta\\}} \\\\[0.5em]\n",
    "&=&\\dfrac{{\\exp\\{\\color{red}\\beta_0}\\}\\exp\\{x_{ij}\\beta\\}}\n",
    "         {\\sum_{k=0}^J{\\exp\\{\\color{red}\\beta_0}\\}\\exp\\{x_{ik}\\beta\\}} \\\\[0.5em]\n",
    "&=&\\dfrac{\\exp\\{x_{ij}\\beta\\}}\n",
    "         {\\sum_{k=0}^J\\exp\\{x_{ik}\\beta\\}}\n",
    "\\end{array}$$\n",
    "\n",
    "\n",
    "- **Solution:** Intercept term needs to be fixed to $\\beta_0=0$.\n",
    "- Otherwise, it is possible to **shift all utilities**\n",
    "(ie, add an arbitrary constant) without changing the ccps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Identification: Multinomial logit\n",
    "- **Similar problem:**\n",
    "$$\\begin{array}{lcl}\n",
    "p_{ij}\n",
    "&=&\\dfrac{\\exp\\{x_{i}(\\beta_j+{\\color{red}\\delta})\\}}\n",
    "         {\\sum_{k=0}^J\\exp\\{x_{i}(\\beta_k+{\\color{red}\\delta})\\}} \\\\[.5em]\n",
    "&=&\\dfrac{{\\color{red}\\exp\\{x_i\\delta\\}}\\exp\\{x_{i}\\beta_j\\}}\n",
    "         {\\sum_{k=0}^J{\\color{red}\\exp\\{x_i\\delta\\}}\\exp\\{x_{i}\\beta_k\\}} \\\\[0.5em]\n",
    "&=&\\dfrac{\\exp\\{x_{i}\\beta_j\\}}\n",
    "                                 {\\sum_{k=0}^J\\exp\\{x_{i}\\beta_k\\}}\n",
    "\\end{array}$$\n",
    "\n",
    "- **Solution:** Define a **baseline alternative $j$** (usually the first one) \n",
    "and set $\\beta_j=0$.\n",
    "- This **normalization** (ie, *identification restriction*) implies that the\n",
    "coefficients are always measured *with respect to the baseline category*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Identification: Scale of utility is irrelevant\n",
    "- Suppose we had the model with extreme value type I errors\n",
    "$$y_i = \\arg \\max_{j\\in\\{0,\\ldots,J\\}} u_{ij}\n",
    "\\qquad\\qquad\n",
    "u_{ij} = x_{ij}\\beta + \\color{red}{\\sigma}\\varepsilon_{ij}$$\n",
    "\n",
    "- Implied logit ccp's are (here for CL)\n",
    "\n",
    "$$\\begin{array}{lcl} \n",
    "p_{ij}\n",
    "&=&\\dfrac{\\exp\\{x_{ij}\\beta/{\\color{red}\\sigma}\\}}\n",
    "         {\\sum_{k=0}^J\\exp\\{x_{ik}\\beta/{\\color{red}\\sigma}\\}} \\\\[.5em]\n",
    "\\end{array}$$\n",
    "\n",
    "- Coefficients are only identified up to scale, $\\beta/\\color{red}{\\sigma}$ \n",
    "- Need the usual scale normalization\n",
    "- **Solution** \n",
    "    - Usually we make the normalization $\\sigma=1$. \n",
    "    - Sometimes we alternatively normalize the scale on one of the coefficients, say $\\beta_k=1$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: Identification in Discrete Choice Models\n",
    "\n",
    "1. **Only differences in utility matter** → Any component that does not vary across alternatives cancels out\n",
    "2. **Utility scale is arbitrary** → Model is only identified up to scale.  \n",
    "\n",
    "3. **Identification conditions depend on variable structure:**  \n",
    "   - **Conditional Logit (CL)**:  \n",
    "     - Attributes vary across alternatives → **Choice-invariant coefficients must be excluded.** \n",
    "   - **Multinomial Logit (MNL)**:  \n",
    "     - Explanatory cariables vary across individuals → **coefficients need to be alternative-specific** \n",
    "     - In models with many alternatives, MNL result in a **huge number of patameters**\n",
    "     - **All alternative-specific coefficients must be measured relative to a baseline alternative.**  \n",
    "   - **In both CL and MNL**: Scale must be normalized, e..g by setting $\\sigma=1$ (or an equivalent restriction).  \n",
    "   - **Models that combines both CL and MNL** →  must take account of all problems above.\n",
    "\n",
    "\n",
    "4. **Key Takeaway:**  \n",
    "   - **Both level and scale normalizations are necessary** for identification.  \n",
    "   - **Interpretation of coefficients depends on normalization choice.**  \n",
    "   - **The same identification issues extend to more general discrete choice models** (e.g., nested logit, mixed logit).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logit and Independence of irrelative alternatives (IIA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Logit $\\rightarrow$  Independence of irrelevant alternatives (IIA)\n",
    "\n",
    "- **Odds ratio** between two alternatives:  \n",
    "  $$\n",
    "  \\frac{P(y=j \\mid x)}{P(y=k \\mid x)} \n",
    "  = \\frac{\\exp(x_j\\beta)/\\sum_l\\exp(x_l\\beta)}\n",
    "         {\\exp(x_k\\beta)/\\sum_l\\exp(x_l\\beta)}\n",
    "  = \\exp((x_j-x_k)\\beta)\n",
    "  $$\n",
    "- **Probability of choosing $j$ over $k$** - does **not depend on any other alternatives** $\\rightarrow$  **IIA property**.  \n",
    "- **Logit restricts substitution patterns**: The impact of changes in attributes applies **proportionally** to all alternatives (we show later that cross elasticities are identical).  \n",
    "\n",
    "### **Why Logit and IIA Is Often Too Restrictive**  \n",
    "- **Airlines:** \n",
    "    - Logit assumes a new **Copenhagen–Stuttgart** route reduces demand **equally** across all other routes, including **Copenhagen–Sydney**. \n",
    "    - In reality, it mainly reduces demand for **Copenhagen–Frankfurt** and **Copenhagen–Munich** (closer substitutes).  \n",
    "- **Car Market:**\n",
    "    - Logit assumes a price drop for **Tesla Model 3** shifts demand **equally** across all car models, including **Ford F-150 Truck**. \n",
    "    - In reality, it mainly shifts demand from other EVs like **Polestar 2** and **BMW i4**.  \n",
    "- **Grocery Stores:** \n",
    "    - Logit assumes that when **Irma** closed, its customers switched **equally** to all other supermarkets, including **Lidl**. \n",
    "    - In reality, most switched to **Meny** or **SuperBrugsen**, which are more similar in price and product selection.  \n",
    "- **Public Transport:** \n",
    "    - Logit assumes adding a **blue bus** takes passengers **equally** from **red bus, car, and train**. \n",
    "    - In reality, it mainly reduces demand for the **red bus**, as they are direct substitutes.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## IIA Example 1: Blue bus/red bus example\n",
    "- Assume two ways of commuting: red bus or car.\n",
    "- Equally likely to be chosen by people:\n",
    "$$P(\\text{red bus})=P(\\text{car})=0.5 \n",
    "\\qquad\\Rightarrow\\qquad\n",
    "\\frac{P(\\text{red bus})}{P(\\text{car})}=1$$\n",
    "- Now, add a blue bus: *identical* to red bus (up to color).\n",
    "- New problem:\n",
    "$$\n",
    "\\begin{cases}\n",
    "P(\\text{blue bus})=P(\\text{red bus}) &\\quad \\text{[identical buses]} \\\\\n",
    "P(\\text{red bus})/P(\\text{car})=1 &\\quad \\text{[must hold (IIA)]}\\\\\n",
    "P(\\text{car})+P(\\text{blue bus})+P(\\text{red bus})=1 &\\quad \\text{[prob. sum to 1]}\n",
    "\\end{cases}$$\n",
    "- Only one solution: $P(\\text{car})=P(\\text{blue bus})=P(\\text{red bus})=1/3$.\n",
    "-We would expect $P(\\text{car})=0.5$, $P(\\text{blue bus})=P(\\text{red bus})=0.25$.\n",
    "\n",
    "\n",
    "**Counterintuitive solution implied by IIA!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "## IIA Example 2: Car example\n",
    "- Suppose $y \\in \\{0,\\ldots,J\\}$ denotes **car type** whose attributes are\n",
    "$x_j=(\\text{price}_j,\\text{size}_j)$.\n",
    "- Assume that **price of car $J$ increases**: \n",
    "$x_{J}^{\\text{new}} = x_{J} + \\Delta$\n",
    "- **Change in probability** (ie, *market share*) **for all other cars \n",
    "$k \\neq J$** are **changed similarly**:\n",
    "$$\\begin{array}{lcl}\n",
    "P(y=k \\mid x^{\\text{new}}) \n",
    "&=& \\dfrac{\\exp\\{x_k'\\beta\\}}\n",
    "         {\\exp\\{\\beta_1\\Delta\\}\\exp\\{x_J\\beta\\}+\\sum_{j\\neq J}\\exp\\{x_j\\beta\\}} \\\\[2em]\n",
    "&=& 1/\\rho \\cdot P(y=k \\mid x^{\\text{old}})\n",
    "\\end{array}$$\n",
    "with: \n",
    "$\\rho=\\left(\\exp\\{\\beta_1\\Delta\\}\\exp\\{x_J\\beta\\}+\\sum_{j\\neq J}\\exp\\{x_j'\\beta\\}\\right)/\\left(\\sum_{j}\\exp\\{x_j\\beta\\}\\right)$\n",
    "\n",
    "\n",
    "\n",
    "- $\\log(\\rho)$ measures the change in consumer surplus after the price change\n",
    "- **How realistic is it that all market shares are impacted proportionally by the same $\\rho$?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Welfare analysis and willingness to pay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Maximal expected utility - the \"log-sum\"\n",
    "- The maximal attainable utility is $\\max_j(u_{it})=\\max_j(v_{it}+\\varepsilon_{it})$\n",
    "- Since the researcher do not observe $\\varepsilon_{it}$ we often compute the the expected welfare which has a closed form in the logit case\n",
    "$$\n",
    "\\mathbb{E}_{\\varepsilon_{01},...,\\varepsilon_{iJ}}\\left[\\max(v_{ij}+\\varepsilon_{ij})\\right]=\\log\\left[\\sum_{j=0}^{J}\\exp(v_{ij})\\right].\n",
    "$$\n",
    "This is some times referred to as the \"log-sum\" or the \"smooth max operator\". If we scale $\\varepsilon_{it}$ with $\\sigma$ we obtain\n",
    "\\begin{eqnarray*}\n",
    " \\mathbb{E}_{\\varepsilon_{01},...,\\varepsilon_{iJ}}\\left[\\max(v_{ij}+\\sigma\\varepsilon_{ij})\\right]\n",
    "&=& \\sigma\\log\\left[\\sum_{j=0}^{J}\\exp(v_{ij}/\\sigma)\\right] \\\\\n",
    "&=& \\max_j v_{ij} + \\sigma\\log\\left[\\sum_{j=0}^{J}\\exp((v_{ij}-\\max_j  v_{ij})/\\sigma)\\right] \n",
    "\\end{eqnarray*}\n",
    "- From the last term we see that $\\varepsilon_{it}$ always adds positively to expected utility if $\\sigma>0$. \n",
    "- This effect is increasing in number of alternatives, so logit implies that consumers have a love of variety.\n",
    "- We also see that the log-sum converges to the max as $\\sigma \\rightarrow 0$ \n",
    "$$\n",
    "\\lim_{\\sigma \\rightarrow 0}\\sigma\\log\\left[\\sum_{j=0}^{J}\\exp(v_{ij}/\\sigma)\\right]= \\max_j v_{ij} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log-sum: The smooth-max operator:\n",
    "<p float=\"center\">\n",
    "    <img src=\"img/max.png\" width=\"500\"/> <img src=\"img/logsum.png\" width=\"500\"/>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Money metric welfare analysis and willingness to pay\n",
    "How to express welfare and substitution in monetary terms? \n",
    "\n",
    "Suppose we have the following specification of indirect utility\n",
    "$$\n",
    "u_{ij}=\\delta_p p_{j} + \\delta_z z_{j} + \\varepsilon_{ij}\n",
    "$$\n",
    "where $p_{j}$ is the price of good $j$ and $z_{j}$ is some other attribute of the good. \n",
    "\n",
    "- The price response, $du_{it}/dp_j=\\delta_p$, is also a measure of **the marginal utility of money**\n",
    "- We can then use the price parameter to compute expected **money metric consumer surplus (CS)** by translating welfare form utility units to monetary units\n",
    "$$\n",
    "E(CS)=1/\\delta_p\\log\\left[\\sum_{j=0}^{J}\\exp(\\delta_p p_{j} + \\delta_z z_{j} )\\right] + C.\n",
    "$$\n",
    "- Now consider a change in prices and attributes that holds utility constant $$du_{ij}=\\delta_p dp_{j} + \\delta_x dz_{j} = 0$$\n",
    "- Here $\\text{wtp}=dp_{j}/dz_{j}=-\\delta_z/\\delta_p$ measures the **willingness to pay** for increase in $z$\n",
    "- Price responses for normal goods are negative, so $\\text{wtp}>0$ if $\\delta_x>0$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Estimation and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Collection and Sources  \n",
    "- **Revealed Preference Data (RP)**\n",
    "  - **Observed real-world choices** from individuals or markets.  \n",
    "  - **Examples:**  \n",
    "    - Danish register data on labor market choices, residental choices, car owenership, etc.  \n",
    "    - Retail scanner data (consumer purchases).  \n",
    "    - Car sales data (market shares, prices, attributes).  \n",
    "  - **Advantage:** Reflects actual behavior under real constraints.  \n",
    "  - **Limitation:** No direct information on unchosen alternatives or counterfactuals.  \n",
    "\n",
    "- **Stated Preference Data (SP)**\n",
    "  - **Hypothetical choices** from surveys or experiments.  \n",
    "  - **Examples:**  \n",
    "    - Discrete choice experiments (DCE) in transport and healthcare.  \n",
    "    - Consumer surveys on willingness to pay for new products.  \n",
    "  - **Advantage:** Allows direct measurement of preferences under controlled conditions.  \n",
    "  - **Limitation:** Risk of hypothetical bias—stated choices may not reflect actual behavior.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Likelihood function\n",
    "- To derive the **likelihood**, all **alternative specific probabilities** are needed.\n",
    "- To simplify notation we abstract from $x$\n",
    "- Define $d_{ij} = \\mathbb{1}(y_i=j)$, such that $\\sum_{j=0}^J d_{ij}=1$.\n",
    "- **Probability of choosing alternative $j$:**\n",
    "$$p_{ij} \\equiv P(y_i = j) = P(d_{ij} = 1, d_{ik}=0\\,\\,\\forall k\\neq j)$$\n",
    "- **Individual likelihood and log-likelihood:**\n",
    "$$\\begin{array}{lcl}\n",
    "L_i(\\theta) &=& \\displaystyle\\prod_{j=1}^J p_{ij}^{d_{ij}} \\\\[1em]\n",
    "\\mathcal{L}_i(\\theta) &\\equiv& \\ln L_i(\\theta) =\n",
    "  \\displaystyle\\sum_{j=0}^J d_{ij} \\ln p_{ij}\n",
    "\\end{array}$$\n",
    "- **How to specify $p_{ij}$?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Types and Sampling  \n",
    "- **Micro Cross-Sectional and Panel Data** \n",
    "  - Sample of size $N$ where unit $i$ is randomly sampled:  \n",
    "  - **Cross-section:** $(y_i, x_{ij})$ is a random draw from the population.  \n",
    "  - **Panel:** $(y_i, x_{ij})$ extends to repeated choices over time.  \n",
    "  - **Panel structure:** $y_i$ is a $T \\times 1$ vector, $x_{ij}$ is a $T \\times K$ matrix with rows $x_{itj}$.  \n",
    "  - **Assumption:** Random sampling over $i$, but not necessarily over $t$.  \n",
    "\n",
    "- **Aggregate (Market Share) Data**\n",
    "    - **Observed:** $(s_{jt}, x_{jt})$, tracking market shares over time and/or across geographic markets.     \n",
    "    - **Interpretation:** Market shares approximate choice probabilities.   \n",
    "    - **Common Panel Features:** Fixed effects for time, product, or geography.  \n",
    "    - **Example:** Grieco et al. (2023) car sales dataset with model-time fixed effects.  \n",
    "\n",
    "- **Key Implications for Estimation** \n",
    "    - **Micro data:** Directly models individual choices and substitution patterns.  \n",
    "    - **Aggregate data:** Requires equilibrium assumptions to infer demand.  \n",
    "    - **Panel structures:** Need models accounting for time dependence and fixed effects.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maximum Likelihood Estimation (MLE) with Cross-Sectional Micro Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Likelihood Function for Discrete Choice Models**\n",
    "- Given observed choices $(y_i)$ and explanatory variables $(x_{i})$, we estimate parameters $\\beta_j$ by maximizing the likelihood function.\n",
    "- Define the **choice indicator**:\n",
    "  $$ d_{ij} = \\mathbb{1}(y_i = j), \\quad \\sum_{j=0}^{J} d_{ij} = 1 $$\n",
    "- The **individual likelihood function**:\n",
    "  $$ L_i(\\beta) = \\prod_{j=1}^{J} p_{ij}^{d_{ij}}, \\quad \\text{where } p_{ij} = P(y_i = j) $$\n",
    "- The **log-likelihood function**:\n",
    "  $$ \\mathcal{L}(\\beta) = \\sum_{i=1}^{N} \\sum_{j=0}^{J} d_{ij} \\ln p_{ij} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **MLE for Multinomial Logit Model (MNL)**\n",
    "For **multinomial logit**, choice probabilities take the form:\n",
    "$$ p_{ij} = \\frac{\\exp(x_{i} \\beta_j)}{\\sum_{k=0}^{J} \\exp(x_{i} \\beta_k)} $$\n",
    "**Log-likelihood contribution** for individual $i$\n",
    "  $$ \\mathcal{L_i}(\\beta) = \n",
    "  \\underbrace{\\sum_{j=1}^J d_{ij} x_{ij}\\beta}_{=x_{iy_i}\\beta} - \n",
    "  \\ln\\left(\\sum_{k=0}^J\\exp\\{x_{ik}\\beta\\}\\right)$$\n",
    "**Maximum likelihood estimator**\n",
    "$$\\hat{\\beta}_{MLE} = \\arg \\max_{\\beta} 1/N\\sum_{n=1}^N\\mathcal{L}(\\beta)$$\n",
    "   - Solve via numerical optimization.\n",
    "   - First-order condition (score function):\n",
    "     $$ \\frac{\\partial \\mathcal{L}}{\\partial \\beta_j} = \\sum_{i=1}^{N} \\left( d_{ij} - p_{ij} \\right) x_i = 0 $$\n",
    "     (i.e. model residuals should be orthogonal to explanatory variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Applicaiton of MNL: Schooling and Employment Choices\n",
    "Replicate Table 16.1 in Wooldridge (2010, p. 645)\n",
    "- **Outcome variable ($y_i$):** Employment status of young men  \n",
    "  - $y_i = 0$: School (**baseline**)  \n",
    "  - $y_i = 1$: Home  \n",
    "  - $y_i = 2$: Work  \n",
    "- **Covariates ($x_i$):**  \n",
    "  - `educ`: Years of education  \n",
    "  - `exper`: Work experience (years)  \n",
    "  - `expersq`: Experience squared  \n",
    "  - `black`: Indicator for Black individuals \n",
    "- **Utility function in MNL ($x_i$):** $u_{ij}=x_i \\beta_j + \\varepsilon_{ij}$ \n",
    "    - Covariates $x_i$ only has variation over $i$\n",
    "    - Coefficients need to be alternative specific, $\\beta_j$\n",
    "- **Normalization for Identification:**  \n",
    "  - We normalize $\\beta_j$ and use `School` as **baseline category**, so $\\beta_{\\text{School}} = 0 $  \n",
    "  - Coefficients for `Home` and `Work` are measured **relative to School** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status\n",
      "2.0       1286\n",
      "1.0        332\n",
      "0.0         99\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>choice</th>\n",
       "      <th>wage</th>\n",
       "      <th>educ</th>\n",
       "      <th>expwc</th>\n",
       "      <th>expbc</th>\n",
       "      <th>expser</th>\n",
       "      <th>manuf</th>\n",
       "      <th>black</th>\n",
       "      <th>...</th>\n",
       "      <th>y84</th>\n",
       "      <th>y85</th>\n",
       "      <th>y86</th>\n",
       "      <th>y87</th>\n",
       "      <th>enroll</th>\n",
       "      <th>employ</th>\n",
       "      <th>attrit</th>\n",
       "      <th>exper</th>\n",
       "      <th>expersq</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15841.410156</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6093.600098</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11017.230469</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6</td>\n",
       "      <td>87</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12137</th>\n",
       "      <td>2226</td>\n",
       "      <td>87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12144</th>\n",
       "      <td>2228</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25762.279297</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12151</th>\n",
       "      <td>2229</td>\n",
       "      <td>87</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23576.240234</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12158</th>\n",
       "      <td>2230</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23886.910156</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>49</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12165</th>\n",
       "      <td>2231</td>\n",
       "      <td>87</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37487.828125</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1717 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  year  choice          wage  educ  expwc  expbc  expser  manuf  \\\n",
       "6         1    87     2.0           NaN    11      0      0       0    0.0   \n",
       "13        2    87     4.0  15841.410156    12      0      3       2    0.0   \n",
       "20        4    87     5.0   6093.600098     9      0      0       0    0.0   \n",
       "27        5    87     3.0  11017.230469     9      2      1       4    0.0   \n",
       "34        6    87     2.0           NaN     8      0      4       0    0.0   \n",
       "...     ...   ...     ...           ...   ...    ...    ...     ...    ...   \n",
       "12137  2226    87     1.0           NaN    13      1      1       0    0.0   \n",
       "12144  2228    87     3.0  25762.279297    16      0      0       0    1.0   \n",
       "12151  2229    87     4.0  23576.240234    11      0      4       2    1.0   \n",
       "12158  2230    87     3.0  23886.910156    12      3      4       0    0.0   \n",
       "12165  2231    87     3.0  37487.828125    16      2      0       0    0.0   \n",
       "\n",
       "       black  ...  y84  y85  y86  y87  enroll  employ  attrit  exper  expersq  \\\n",
       "6          1  ...    0    0    0    1       0       0       0      0        0   \n",
       "13         1  ...    0    0    0    1       0       1       0      5       25   \n",
       "20         1  ...    0    0    0    1       0       1       0      0        0   \n",
       "27         1  ...    0    0    0    1       0       1       0      7       49   \n",
       "34         1  ...    0    0    0    1       0       0       0      4       16   \n",
       "...      ...  ...  ...  ...  ...  ...     ...     ...     ...    ...      ...   \n",
       "12137      0  ...    0    0    0    1       1       0       0      2        4   \n",
       "12144      0  ...    0    0    0    1       0       1       0      0        0   \n",
       "12151      0  ...    0    0    0    1       0       1       0      6       36   \n",
       "12158      0  ...    0    0    0    1       0       1       0      7       49   \n",
       "12165      0  ...    0    0    0    1       0       1       0      2        4   \n",
       "\n",
       "       status  \n",
       "6         1.0  \n",
       "13        2.0  \n",
       "20        2.0  \n",
       "27        2.0  \n",
       "34        1.0  \n",
       "...       ...  \n",
       "12137     0.0  \n",
       "12144     2.0  \n",
       "12151     2.0  \n",
       "12158     2.0  \n",
       "12165     2.0  \n",
       "\n",
       "[1717 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "df = pd.read_stata('keane.dta')\n",
    "df=df[df['year']==87].dropna(subset=['status', 'educ', 'exper', 'expersq', 'black'])\n",
    "x=['educ', 'exper', 'expersq', 'black']\n",
    "y=['status'] # status (0: school, 1: home, 2: work)\n",
    "print(df[y].value_counts())\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Parameter estimates - school as reference kategory\n",
    "See Table 16.1 in Wooldridge(2010, p. 645)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528746\n",
      "         Iterations 8\n",
      "\n",
      "status: 0=school (baseline), 1=home, 2=work\n",
      "\n",
      "                           MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 status   No. Observations:                 1717\n",
      "Model:                        MNLogit   Df Residuals:                     1707\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Mar 2025   Pseudo R-squ.:                  0.2433\n",
      "Time:                        15:20:47   Log-Likelihood:                -907.86\n",
      "converged:                       True   LL-Null:                       -1199.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.383e-121\n",
      "==============================================================================\n",
      "  status=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         10.2779      1.133      9.069      0.000       8.057      12.499\n",
      "educ          -0.6736      0.070     -9.637      0.000      -0.811      -0.537\n",
      "exper         -0.1062      0.173     -0.613      0.540      -0.446       0.233\n",
      "expersq       -0.0125      0.025     -0.496      0.620      -0.062       0.037\n",
      "black          0.8130      0.303      2.686      0.007       0.220       1.406\n",
      "------------------------------------------------------------------------------\n",
      "  status=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          5.5438      1.086      5.103      0.000       3.414       7.673\n",
      "educ          -0.3147      0.065     -4.833      0.000      -0.442      -0.187\n",
      "exper          0.8487      0.157      5.406      0.000       0.541       1.156\n",
      "expersq       -0.0773      0.023     -3.372      0.001      -0.122      -0.032\n",
      "black          0.3114      0.282      1.106      0.269      -0.240       0.863\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Estimimate MNL\n",
    "mnl_keane=sm.MNLogit(df[y], sm.add_constant(df[x]))\n",
    "result=mnl_keane.fit()\n",
    "print('\\nstatus: 0=school (baseline), 1=home, 2=work\\n\\n', result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##  Parameter estimates - Try work as reference kategory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.528746\n",
      "         Iterations 8\n",
      "\n",
      "status_w0: 2=work (baseline), 0=school, 1=home\n",
      "\n",
      "                           MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:              status_w0   No. Observations:                 1717\n",
      "Model:                        MNLogit   Df Residuals:                     1707\n",
      "Method:                           MLE   Df Model:                            8\n",
      "Date:                Mon, 03 Mar 2025   Pseudo R-squ.:                  0.2433\n",
      "Time:                        15:20:47   Log-Likelihood:                -907.86\n",
      "converged:                       True   LL-Null:                       -1199.7\n",
      "Covariance Type:            nonrobust   LLR p-value:                7.383e-121\n",
      "===============================================================================\n",
      "status_w0=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          -5.5438      1.086     -5.103      0.000      -7.673      -3.414\n",
      "educ            0.3147      0.065      4.833      0.000       0.187       0.442\n",
      "exper          -0.8487      0.157     -5.406      0.000      -1.156      -0.541\n",
      "expersq         0.0773      0.023      3.372      0.001       0.032       0.122\n",
      "black          -0.3114      0.282     -1.106      0.269      -0.863       0.240\n",
      "-------------------------------------------------------------------------------\n",
      "status_w0=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           4.7341      0.462     10.253      0.000       3.829       5.639\n",
      "educ           -0.3590      0.032    -11.238      0.000      -0.422      -0.296\n",
      "exper          -0.9550      0.097     -9.882      0.000      -1.144      -0.766\n",
      "expersq         0.0648      0.013      5.076      0.000       0.040       0.090\n",
      "black           0.5017      0.148      3.380      0.001       0.211       0.793\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "df['status_w0'] = df[y].replace({0: 1, 1: 2, 2: 0})  # Makes 'work' (2) the baseline\n",
    "mnl_keane_w0 = sm.MNLogit(df['status_w0'], sm.add_constant(df[x]))\n",
    "result_w0 = mnl_keane_w0.fit()\n",
    "print('\\nstatus_w0: 2=work (baseline), 0=school, 1=home\\n\\n', result_w0.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interpreting MNL Estimates: $\\beta_j$ is Hard to Interpret  \n",
    "- **Multinomial Logit Choice Probabilities**\n",
    "$$\n",
    "p_{ij} = \\frac{\\exp\\{x_{i}\\beta_j\\}}{\\sum_{k=0}^J\\exp\\{x_{i}\\beta_k\\}}\n",
    "$$  \n",
    "\n",
    "- **Log Odds Ratio (Relative to Baseline $j=0$)**  \n",
    "$$\n",
    "\\ln\\frac{P(y_i=j\\mid x_i)}{P(y_i=0\\mid x_i)} = \\ln\\frac{\\exp\\{x_{i}\\beta_j\\}/\\sum_{k=0}^J\\exp\\{x_{i}\\beta_k\\}}{\\exp\\{x_{i}\\beta_j\\}/\\sum_{k=0}^J\\exp\\{x_{i}\\beta_k\\}}=x_i(\\beta_j-\\beta_0) = x_i\\beta_j \n",
    "$$  \n",
    "    - **Linear in $x_i$** \n",
    "    - $\\beta_j$ measures change in **log odds** between alternative $j$ and baseline.  \n",
    "    \n",
    "- **Marginal Effects** \n",
    "$$\n",
    "\\frac{\\partial}{\\partial x_i}P(y_i=j \\mid x_i)\n",
    "= p_{ij}\\left(\\beta_j-\\sum_{l=0}^J p_{il}\\beta_l\\right) \n",
    "$$  \n",
    "    - Depend on **all $\\beta_k$** and choice probabilities.  \n",
    "    - **Sign of $\\beta_j$ alone does not determine effect on $P(y_i=j)$!**  \n",
    "\n",
    "- **Key Takeaways** \n",
    "    - Unlike **binary logit**, **MNL $\\beta_j$ does not directly indicate direction of effect**.  \n",
    "    - **Marginal effects** provide the correct interpretation → Compute them! \n",
    "    - If we average over all observations, we get *Average Marginal Effects* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Average Marginal Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "status: 0=school, 1=home, 2=work\n",
      "\n",
      "        MNLogit Marginal Effects      \n",
      "=====================================\n",
      "Dep. Variable:                 status\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "==============================================================================\n",
      "  status=0      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "educ           0.0174      0.003      5.981      0.000       0.012       0.023\n",
      "exper         -0.0313      0.007     -4.629      0.000      -0.045      -0.018\n",
      "expersq        0.0030      0.001      2.937      0.003       0.001       0.005\n",
      "black         -0.0184      0.013     -1.435      0.151      -0.043       0.007\n",
      "------------------------------------------------------------------------------\n",
      "  status=1      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "educ          -0.0429      0.003    -14.312      0.000      -0.049      -0.037\n",
      "exper         -0.1006      0.010    -10.429      0.000      -0.120      -0.082\n",
      "expersq        0.0067      0.001      4.811      0.000       0.004       0.009\n",
      "black          0.0590      0.016      3.587      0.000       0.027       0.091\n",
      "------------------------------------------------------------------------------\n",
      "  status=2      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "educ           0.0256      0.004      6.276      0.000       0.018       0.034\n",
      "exper          0.1319      0.011     12.327      0.000       0.111       0.153\n",
      "expersq       -0.0097      0.002     -6.122      0.000      -0.013      -0.007\n",
      "black         -0.0406      0.020     -2.057      0.040      -0.079      -0.002\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "margeff=result.get_margeff(at='overall') # try at=‘mean' or 'median', or 'zero' \n",
    "print('status: 0=school, 1=home, 2=work\\n\\n', margeff.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Conclusion: Why MNL Coefficients Are Hard to Interpret**  \n",
    "\n",
    "### **1. Normalization Affects Coefficients**  \n",
    "- $\\beta_j$ is measured **relative to the baseline** → Changing baseline shifts all $\\beta_j$.  \n",
    "- Example: $\\beta_{\\text{educ}}$ for **Home** and **Work** changes when switching from **School** to **Work**.  \n",
    "\n",
    "### **2. Coefficients ≠ Direct Effects on Probabilities**  \n",
    "- $\\beta_j$ affects **log odds, not choice probabilities**.  \n",
    "- **Sign of $\\beta_j$ does not determine the sign of marginal effects**.  \n",
    "- Example: $\\beta_{\\text{educ}} < 0$ for both **Home** and **Work**, but dy/dx is **positive for Work, negative for Home**.  \n",
    "\n",
    "### **3. Marginal Effects Are Necessary**  \n",
    "- Depend on **both $\\beta_j$ and choice probabilities $p_{ij}$**\n",
    "- We compute Average Marginal Effects to summarize\n",
    "\n",
    "**🔹 Key Takeaway:** Always interpret **marginal effects, not raw coefficients**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Conditional Logit: From Theory to Implementation**  \n",
    "**Model Setup: Conditional Logit (CL)**  \n",
    "- **Utility specification:** $u_{ij} = x_{ij} \\beta + \\varepsilon_{ij}$  \n",
    "- **Key difference from MNL:** Covariates ($x_{ij}$) **vary across alternatives** instead of individuals.  \n",
    "\n",
    "**Construct** the entire **MLE estimation pipeline** from scratch using `mestim.py` and `discrete_choice.py`:  \n",
    "1. **Utility function:** How observed attributes influence choices.  \n",
    "2. **Choice probabilities (CCPs) and log-likelihood:** From utility to ccps to log-likelihood for indivdual $i$.  \n",
    "3. **MLE, objective and optimization** Set up objective and scores for optimization and pass it to `mestim.py` to obtain MLE and standard errors.  \n",
    "4. **Simulation Study:** Verifying implementation.  \n",
    "5. **Own and Cross price elasticities:** Understanding substition patterns\n",
    "6. **Empirical Application:** Choice of cooling and heating system \n",
    "\n",
    "**Key Objectives**  \n",
    "- **Move beyond “black-box” estimation** to understand what’s happening.  \n",
    "- **Prepare for more advanced models** (Nested Logit, BLP, Structural Estimation).  \n",
    "- **Bridge from theory to practical implementation in Python.**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Before we move on, let's load some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# routines for simulation and estimation of conditional logit\n",
    "from discrete_choice import *\n",
    "import discrete_choice as ds\n",
    "import mestim as M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Step 1: Utility Function in Conditional Logit**  \n",
    "\n",
    "- **Choice rule:** Individuals select $j$ that maximizes:  \n",
    "  $$ u_{ij} = v_{ij} + \\varepsilon_{ij}, \\quad v_{ij} = x_{ij} \\beta $$  \n",
    "- $K$ covariates $x_{ij}$ that all vary across alternatives (and potentially with individuals) \n",
    "- **Dimensions:**  \n",
    "  - $N$: Individuals, $J$: Alternatives, $K$: Covariates  \n",
    "  - $x$: $(N, J, K)$, $\\beta$: $(K, 1)$, $v$: $(N, J)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chocie specific utility: (N x J):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.12830706,  0.54491488,  0.09584645],\n",
       "       [-0.72356048,  0.5771351 ,  0.14161433],\n",
       "       [ 0.4467849 , -1.19333869,  0.38356442],\n",
       "       [-0.20424138,  0.41310552, -0.1809353 ],\n",
       "       [ 0.3104013 , -0.25052216, -0.27786539]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def utility(theta, x):\n",
    "\tN, J, K = x.shape       # N: Individuals, J: Alternatives, K: Covariates\n",
    "\tu = x @ theta           # Compute deterministic utility v_ij = x_ij * beta\n",
    "\treturn u.reshape(N, J)  # Reshape to match (N, J) structure\n",
    "\n",
    "β=[[0.5], [-0.2]]           \n",
    "N, J, K = 5, 3, len(β)\n",
    "x=np.random.randn(N, J, K) \n",
    "print('Chocie specific utility: (N x J):')\n",
    "utility(β, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Step 2: Choice Probabilities & Log-Likelihood Contribution**  \n",
    "- **Conditional Choice Probabilities (CCPs):**  \n",
    "$$ p_{ij} = \\frac{\\exp(v_{ij})}{\\sum_{k=1}^{J} \\exp(v_{ik})} $$  \n",
    "- **Log-likelihood contribution:**  \n",
    "$$ \\mathcal{L}_i = v_{iy_i} - \\log \\sum_{k=1}^{J} \\exp(v_{ik}) $$ \n",
    "- **Interpretation of Log-likelihood:**  \n",
    "    - First term $v_{iy_i}$ captures the realized utility of the chosen alternative.\n",
    "    - Second term $\\log \\sum_{k} \\exp(v_{ik})$ represents the expected maximum utility under EV1 errors.\n",
    "  $$ E(\\max_j(u_{ij})=\\log \\sum_{k} \\exp(v_{ik}) $$ \n",
    "    - The log-likelihood thus measures the difference between the realized utility at the chosen alternative and the expected max utility.\n",
    "    - So MLE selects utility parameters $\\beta$ so that observed choices correspond to alternatives with the highest expected utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python implementation of CCPs, Emax, and log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def logsum(v, sigma=1): \n",
    "    # Expected max utility under EV1 errors\n",
    "    # v: (N, J) matrix of deterministic utilities\n",
    "    # Returns: (N, 1) vector of expected maximum utilities\n",
    "    max_v = v.max(axis=1, keepdims=True)  \n",
    "    return max_v + sigma * np.log(np.sum(np.exp((v - max_v) / sigma), axis=1, keepdims=True))\n",
    "\n",
    "def logccp(v, y=None, sigma=1):\n",
    "    # Compute log-conditional choice probabilities or log-likelihood contribution\n",
    "    # v: (N, J) matrix of deterministic utilities\n",
    "    # y: (N,) vector of chosen alternatives (optional)\n",
    "    # Returns: (N, J) matrix of log choice probabilities if y is None\n",
    "    #          (N, 1) vector of log-likelihood values if y is provided\n",
    "    ev = logsum(v, sigma)  \n",
    "    if y is not None:  \t\t\n",
    "        N, J = v.shape\n",
    "        idx = y + J * np.arange(N)  # Flattened index selection for chosen alternative\n",
    "        v = v.reshape(N * J, 1)[idx]  # Select chosen alternative's utility (N, 1)\n",
    "    return (v - ev) / sigma  \n",
    "\n",
    "def ccp(v, y=None, sigma=1):\n",
    "    # Compute conditional choice probabilities\n",
    "    # v: (N, J) matrix of deterministic utilities\n",
    "    # Returns: (N, J) matrix of probabilities if y is None\n",
    "    #          (N, 1) vector of likelihood values if y is provided\n",
    "    return np.exp(logccp(v, y, sigma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Step 3: MLE, sample objective function and it's derivatives**  \n",
    "1. **Maximum Likelihood Estimator**  \n",
    "We estimate $ \\beta $ by maximizing the sample average log-likelihood:  \n",
    "$$\n",
    "\\hat{\\beta}_{MLE} = \\arg \\max_{\\beta} \\frac{1}{N} \\sum_{i=1}^{N} \\mathcal{L}_i(\\beta) \n",
    "$$\n",
    "or equivalently minimizing sample objective function $Q_N(\\beta)$ defined as the negative log-likelihood:\n",
    "\\begin{align}\n",
    "\\hat{\\beta}_{MLE} &=\\arg  \\min_{\\beta} -\\frac{1}{N} \\sum_{i=1}^{N} \\mathcal{L}_i(\\beta)\n",
    "=\\arg  \\min_{\\beta} \\underbrace{-\\frac{1}{N} \\sum_{i=1}^{N}  \\left( v_{iy_i} - \\log \\sum_{k=1}^{J} \\exp(v_{ik})\\right)}_{Q_N(\\beta) } \n",
    "\\end{align}\n",
    "\n",
    "1. **First-Order Condition (FOC) and Interpretation**  \n",
    "The **gradient** (score function) must be zero at the optimum   \n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial Q_N(\\beta)}{\\partial \\beta} = - \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\partial v_{iy_i}/\\partial \\beta - \\sum_{j=1}^{J} p_{ij}(\\beta) \\partial v_{ij} / \\partial \\beta \\right) \n",
    "= - \\frac{1}{N} \\sum_{i=1}^{N} \\underbrace{\\left(x_{iy_i} - \\sum_{j=1}^{J} p_{ij}(\\beta) x_{ij} \\right) }_{s_i(\\beta)}\n",
    "= 0\n",
    "\\end{align}\n",
    "$$\n",
    "    - With linear utility $v_{ij} = x_{ij}\\beta$, we have $\\partial v_{ij} / \\partial \\beta = x_{ij}$\n",
    "    - Derivative of $\\log \\sum_{k=1}^{J} \\exp(v_{ik})$ wrt change in $v_{ij}$ is $p_{ij}=\\frac{\\exp(v_{ij})}{\\sum_{k=1}^{J} \\exp(v_{ik})}$\n",
    "    - $ x_{iy_i} $ are attributes for the chosen alternative.  \n",
    "    - $ p_{ij}(\\beta) $ are logit choice probabilities (as function of $\\beta$).  \n",
    "- **Interpretation:** \n",
    "MLE sets $\\beta$ so observed attributes $x_{iy_i}$ on average matches the expected ones $\\sum_j p_{ij}(\\beta)x_{ij}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python implementation of objective function, $Q_N(\\beta)$, scores, $s_i(\\beta)$ and gradient, $\\partial Q_N(\\beta)/\\partial \\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def Q_clogit(theta, y, x, out='Q'):\n",
    "    \"\"\"\n",
    "    Sample log-likelihood and its derivatives for Conditional Logit.\n",
    "    \n",
    "    Parameters:\n",
    "    - theta: (K, 1) parameter vector\n",
    "    - y: (N,) observed choices\n",
    "    - x: (N, J, K) covariates (varying across alternatives)\n",
    "    - out: 'Q' for negative log-likelihood, 's_i' for individual scores, 'dQ' for gradient of Q.\n",
    "\n",
    "    Returns:\n",
    "    - Negative mean log-likelihood (if out='Q')\n",
    "    - Individual score contributions (if out='s_i')\n",
    "    - Gradient (if out='dQ')\n",
    "    \"\"\"\n",
    "    \n",
    "    N, J, K = x.shape\n",
    "    v = utility(theta, x)  # Compute deterministic utility v_ij = x_ij * beta\n",
    "    ll_i = logccp(v, y)   # Compute log-likelihood contribution\n",
    "\n",
    "    if out == 'Q': \n",
    "        return -np.mean(ll_i)  # Sample objective function (negative mean log-likelihood)\n",
    "\n",
    "    # Compute (s_i) or gradient (dQ)\n",
    "    p = ccp(v)  # Compute choice probabilities p_ij\n",
    "    x_iy = x.reshape(N * J, K)[y + J * np.arange(N), :]  # Extract covariates for chosen alternative\n",
    "    s_i = x_iy - np.sum(p.reshape(N, J, 1) * x, axis=1)  # Score function: residual of x_iy - E[x|choice]\n",
    "\n",
    "    return s_i if out == 's_i' else -np.mean(s_i, axis=0)  # Return individual scores or gradient (dQ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Python implementation of Conditional Logit (minimize $Q_N$ and report results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from discrete_choice import print_output\n",
    "def clogit(y, x, cov_type='Ainv', theta0=None, deriv=1, quiet=False,  xvars=None): \n",
    "    \"\"\"\n",
    "    Estimates a Conditional Logit model using M-estimation.\n",
    "    \n",
    "    Parameters:\n",
    "    - y: (N,) vector of observed choices (0, 1, ..., J-1)\n",
    "    - x: (N, J, K) covariate matrix (varying across alternatives)\n",
    "    - cov_type: Type of variance estimation ('Ainv', 'Binv', 'sandwich')\n",
    "    - theta0: Initial parameter guess (default: zeros)\n",
    "    - deriv: Order of derivative (0 for none, 1 for first-order)\n",
    "    - quiet: Suppress output if True\n",
    "    \n",
    "    Returns:\n",
    "    - res: Dictionary with estimates, standard errors, and diagnostics\n",
    "    \"\"\"\n",
    "    N, J, K, _, _, xvars = labels(x, xvars)  # Extract dimensions and variable names\n",
    "    \n",
    "    Qfun = lambda theta, out: Q_clogit(theta, y, x, out)  # Define sample objective function\n",
    "    theta0 = np.zeros(K) if theta0 is None else theta0  # Default start values\n",
    "    res = M.estimation(Qfun, theta0, deriv, cov_type, parnames=xvars)  # Estimate via MLE\n",
    "    res.update({'yvar': 'y', 'xvars': xvars, 'N': N, 'K': K, 'n': N})  # Store model details\n",
    "\n",
    "    if not quiet:    \n",
    "        print('Conditional Logit Estimation')\n",
    "        print('Initial log-likelihood:', -Qfun(theta0, 'Q'))\n",
    "        print('Initial gradient:\\n', -Qfun(theta0, 'dQ'))\n",
    "        print_output(res)\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 4: Simulation Study: Simulate data and estimate conditional logit using MLE\n",
    "**Data Generation Process (DGP)**  \n",
    "\\begin{align} \n",
    "y_i &= \\arg \\max_j x_{ij} \\beta + \\varepsilon_{ij}, \\quad \\varepsilon_{ij} \\sim \\text{i.i.d. EV1}  \n",
    "\\\\x_{ij} &\\sim \\mathcal{N}(\\mu_j, I_K), \\quad \\mu_j \\text{ increasing from 3 to 5 across } j  \n",
    "\\end{align}\n",
    "\n",
    "**Experiment**: \n",
    "- Change parameters, sample size, and number of alternatives\n",
    "- Inspect parameter estimates, standard errors and cpu time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "Conditional Logit Estimation\n",
      "Initial log-likelihood: -1.6094379124340994\n",
      "Initial gradient:\n",
      " [0.8227063  0.23881931 1.30452475]\n",
      "Dep. var. : y \n",
      "\n",
      "parnames      theta_hat          se    t-values         jac\n",
      "----------  -----------  ----------  ----------  ----------\n",
      "var0            0.77695     0.18055     4.30319     0.00000\n",
      "var1           -0.77559     0.16762    -4.62714     0.00001\n",
      "var2            1.78133     0.23386     7.61713    -0.00000\n",
      "# of observations : 100\n",
      "# log-likelihood. : -68.94477214560135 \n",
      "\n",
      "Iteration info: 11 iterations, 12 evaluations of objective, and 12 evaluations of gradients\n",
      "Elapsed time: 0.0027 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "J=5         # number of alternatives index j=0,..,J-1\n",
    "N=100        # number of observations\n",
    "theta=np.array([1, -1, 2])  # True parameters\n",
    "dta=ds.sim_data(N, J, theta);\n",
    "res=clogit(dta['y'], dta['x'], deriv=1)  # Estimate c-logit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Step 5: Marginal Effects, Own and Cross elasticities:\n",
    "**Marginal Effects in Conditional Logit**  \n",
    "\n",
    "We start from the conditional logit choice probability:  \n",
    "$$\n",
    "p_{ij} = \\frac{\\exp(v_{ij} )}{\\sum_{k=1}^{J} \\exp(v_{ik})}\n",
    "$$\n",
    "\n",
    "To compute the **marginal effect** of a change in $x_{ik}$, we differentiate $p_{ij}$ with respect to $x_{ik}$:\n",
    "\n",
    "\\begin{align}\n",
    "\\frac{\\partial p_{ij}}{\\partial x_{ik}} &= \n",
    "\\frac{\\mathbb{1}(j = k) \\exp(v_{ij} )  \\sum_{m} \\exp(v_{im}) \n",
    "- \\exp(v_{ij}) \\exp(v_{ik})}\n",
    "{(\\sum_{m} \\exp(v_{im}))^2}  \\frac{\\partial v_{ik}}{ \\partial x_{ik}}\n",
    "\\\\&=p_{ij} (\\mathbb{1}(j=k) - p_{ik}) \\frac{\\partial v_{ik}}{ \\partial x_{ik}}\n",
    "\\end{align}\n",
    "\n",
    "With linear utility $\\frac{\\partial v_{ik}}{ \\partial x_{ik}}=\\beta$, we obtain:  \n",
    "$$\n",
    "\\frac{\\partial p_{ij}}{\\partial x_{ik}} = \n",
    "p_{ij}  (\\mathbb{1}(j=k) - p_{ik})\\beta\n",
    "$$\n",
    "\n",
    "**Derivatives sum to zero** (since probabilities always sum to 1)  \n",
    "  $$\\sum_{j=1}^{J} \\frac{\\partial p_{ij}}{\\partial x_{ik}} = 0.$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Properties of Partial Effects and Average Partial Effects (APE)\n",
    "- **Own effect (marginal effect of $x_{ij}$ on $p_{ij}$):**  \n",
    " $\\frac{\\partial p_{ij}}{\\partial x_{ij}} = p_{ij} (1 - p_{ij}) \\beta  \\quad (\\text{same sign as } \\beta)$\n",
    "\n",
    "- **Cross effect (effect of $x_{ik}$ on $p_{ij}$ for $j \\neq k$):**  \n",
    "$\\frac{\\partial p_{ij}}{\\partial x_{ik}} = -p_{ij} p_{ik} \\beta  \\quad (\\text{opposite sign of } \\beta)$\n",
    "\n",
    "- **With linear utility **all goods are substitutes in logit** \n",
    ":** \n",
    "  \n",
    "  - If $x_{ik}$ is a **desirable attribute**, i.e., $\\beta > 0$, then increasing $x_{ik}$ increases the probability of choosing alternative $k$ and decreases the probability of choosing all other alternatives.  \n",
    "  - If $x_{ik}=\\text{price}_{ik}$ of a good $k$ and $\\beta_{\\text{price}} < 0$, then increasing the price **reduces the probability of choosing good $k$** while **increasing the probability of choosing other alternative goods**.  \n",
    "\n",
    "- **Average Partial Effects (APE)**  \n",
    "(Averaging over individuals)  \n",
    "$$\n",
    "\\mathbb{E} \\left[ \\frac{\\partial p_{ij}}{\\partial x_{ij}} \\right] = \\mathbb{E} \\left[ p_{ij} (1 - p_{ij}) \\right] \\beta.\n",
    "$$  \n",
    "    - Recall $p_{ij} (1 - p_{ij})$ is the variance of a Bernoulli variable\n",
    "    - APE scales $\\beta$ by $\\mathbb{E} \\left[ p_{ij} (1 - p_{ij}) \\right]$ which is the expected variation in choice of $j$.\n",
    "    - If $p_{ij}$ is close to 0 or 1 for all individuals, the marginal effect is small since choices are almost deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute Average Partial Effects (APE)\n",
    "Below we compute derivatives averaged over the sample, i.e. average partial effects (APE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "APE: Average change in ['p0', 'p1', 'p2', 'p3', 'p4']\n",
      "    - w.r.t. change in ['alt0', 'alt1', 'alt2', 'alt3', 'alt4'] \n",
      "    - for attribute m=0 (var0) with coefficient θ_0=[0.7769]\n",
      "              p0          p1          p2          p3          p4\n",
      "----  ----------  ----------  ----------  ----------  ----------\n",
      "alt0     0.02197    -0.00264    -0.00428    -0.00886    -0.00619\n",
      "alt1    -0.00264     0.03886    -0.00634    -0.01232    -0.01755\n",
      "alt2    -0.00428    -0.00634     0.05165    -0.01712    -0.02390\n",
      "alt3    -0.00886    -0.01232    -0.01712     0.08224    -0.04393\n",
      "alt4    -0.00619    -0.01755    -0.02390    -0.04393     0.09158\n",
      "\n",
      "Check: Derivatives of pj should sum to 0 over all alternatives: True\n"
     ]
    }
   ],
   "source": [
    "from discrete_choice import labels \n",
    "def APE_var(theta, x, m=0, xvars=None, alternatives=None, quiet=False):    \n",
    "    N, J, K, palt, xalt, xvars = labels(x, xvars, alternatives) # Extract dimensions and labels\n",
    "    \n",
    "    # Compute APE: Expected marginal effects of x_{ik} on p_{ij}\n",
    "    p = ccp(utility(theta, x))  # Compute choice probabilities p_ij\n",
    "    E = np.empty((J, J)) # Initialize APE matrix     \n",
    "    for j in range(J):  # Loop over alternatives (j)\n",
    "        for k in range(J):  # Loop over alternatives (k)\n",
    "            E[k, j] = np.mean(p[:, j] * theta[m] * (1 * (j == k) - p[:, k]), axis=0)\n",
    "\n",
    "    # Print APE results if quiet=False\n",
    "    if not quiet:  \n",
    "        print(f\"\\nAPE: Average change in {palt}\\n    - w.r.t. change in {xalt} \\n    - for attribute m={m} ({xvars[m]}) with coefficient θ_{m}={theta[m].round(4)}\")\n",
    "        print(tabulate(np.c_[xalt, E], headers=palt, floatfmt=\"10.5f\"))\n",
    "\n",
    "    return E\n",
    "\n",
    "dydx = APE_var(res.theta_hat, dta['x'], m=0) # Compute APE for the first attribute (m=0) - Try other attributes\n",
    "print(\"\\nCheck: Derivatives of pj should sum to 0 over all alternatives:\", np.allclose(np.sum(dydx, axis=1), 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Elasticities in Conditional Logit\n",
    "Economists often measure responses in terms of **elasticities**, as they normalize for units of measurement.\n",
    "\n",
    "- **Elasticity of $p_{ij}$ w.r.t. an alternative-specific attribute $x_{ik}$**:\n",
    "\n",
    "  $$\n",
    "  E_{j, x_{ik}}= \\frac{x_{ik}}{p_{ij}}\\frac{\\partial p_{ij}}{\\partial x_{ik}}\n",
    "  \\quad=\\quad \\frac{x_{ik}}{p_{ij}}  p_{ij}\\left(\\mathbb{1}(k=j)-p_{ik}\\right)\\beta \n",
    "  \\quad=\\quad \\left(\\mathbb{1}(k=j)-p_{ik}\\right) x_{ik}\\beta \n",
    "  $$\n",
    "- **Own elasticity** (i.e. when $k=j$)\n",
    "\n",
    "$$E_{j, x_{ik}}= \n",
    "\\quad=\\quad (1-p_{ik})x_{ik}\\beta $$\n",
    "\n",
    "- **The cross elasticity** (i.e. when $k\\ne j$) is completely independent of $j$\n",
    "\n",
    "$$E_{j, x_{ik}}= \n",
    "\\quad=\\quad -p_{ik} x_{ik}\\beta $$\n",
    "\n",
    "### **Restrictive and Unrealistic Substitution Patterns**\n",
    "- A change in an attribute of alternative $k$ **affects all other alternatives equally in percentage terms**.  \n",
    "- Logit imposes the **Independence of Irrelevant Alternatives (IIA)** property, leading to **proportional substitution patterns**.  \n",
    "- **IIA implies that relative odds between any two alternatives remain constant, regardless of the presence or attributes of other choices**.  \n",
    "- This is often **unrealistic**, motivating **generalized models such as Nested Logit or Mixed Logit**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compute elasticities\n",
    "Note that the **cross elasticity** $E_{j, x_{ik}} = - p_{ik} x_{ik} \\beta$ are identical for all $j\\ne k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elasticity wrt change in var0\n",
      "              p0          p1          p2          p3          p4\n",
      "----  ----------  ----------  ----------  ----------  ----------\n",
      "alt0     2.23256    -0.10572    -0.10572    -0.10572    -0.10572\n",
      "alt1    -0.23759     2.51907    -0.23759    -0.23759    -0.23759\n",
      "alt2    -0.54916    -0.54916     2.58167    -0.54916    -0.54916\n",
      "alt3    -1.01178    -1.01178    -1.01178     2.54769    -1.01178\n",
      "alt4    -1.85728    -1.85728    -1.85728    -1.85728     1.96909\n"
     ]
    }
   ],
   "source": [
    "def Ematrix_var(theta, x, m=0, xvars=None, alternatives=None, quiet=False):\n",
    "\t# matrix of elasticities with respect ot a change in attribute m\n",
    "\tN, J, K, palt, xalt, xvars = labels(x, xvars, alternatives)\n",
    "\tp=ccp(utility(theta, x))\n",
    "\tE=np.empty((J,J))\n",
    "\tfor j in range(J):\n",
    "\t    for k in range(J):\n",
    "\t        E[k, j]=np.mean(x[:,k,m]*theta[m]*(1*(j==k)-p[:,k]), axis=0)\n",
    "\tif not quiet: \n",
    "\t    print('\\nElasticity wrt change in', xvars[m])\n",
    "\t    print(tabulate(np.c_[xalt, E], headers=palt,floatfmt=\"10.5f\"))\n",
    "\treturn E\n",
    "E=Ematrix_var(res.theta_hat, dta['x'], m=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Own and Cross-Elasticities in Conditional Logit**  \n",
    "- **Own elasticity $E_{j, x_{ij}}$**  \n",
    "  - **Percentage change in probability of choosing $j$** when **$x_{ij}$ changes by 1%**.  \n",
    "- **Cross elasticity $E_{j, x_{ik}}$ ($j \\neq k$)**  \n",
    "  - **Percentage change in probability of choosing $j$** when **$x_{ik}$ (an attribute of alternative $k$) changes by 1%**.  \n",
    "  - If $x_{ik}$ is **price**, this is a **cross-price elasticity**, which is widely used in demand analysis.  \n",
    "  - Logit forces **all cross elasticities to be the same for all alternatives**, which is a major limitation.\n",
    "\n",
    "\n",
    "Since **cross elasticity** $E_{j, x_{ik}} = - p_{ik} x_{ik} \\beta$ is **identical for all $j\\ne k$**, we often **only report a single cross elasticity per attribute**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Own elasticity\n",
      "            var0        var1        var2\n",
      "----  ----------  ----------  ----------\n",
      "alt0     2.23256    -2.29230     4.92988\n",
      "alt1     2.51907    -2.55836     5.91574\n",
      "alt2     2.58167    -2.69933     5.63306\n",
      "alt3     2.54769    -2.64599     5.67309\n",
      "alt4     1.96909    -2.05912     4.45909\n",
      "\n",
      "Cross-Elasticity\n",
      "            var0        var1        var2\n",
      "----  ----------  ----------  ----------\n",
      "alt0    -0.10572     0.06209    -0.26968\n",
      "alt1    -0.23759     0.18078    -0.64849\n",
      "alt2    -0.54916     0.44568    -1.43802\n",
      "alt3    -1.01178     0.84390    -2.43579\n",
      "alt4    -1.85728     1.76286    -4.76546\n"
     ]
    }
   ],
   "source": [
    "E_own=ds.Ematrix_own(res.theta_hat, dta['x'])\n",
    "E_cross=ds.Ematrix_cross(res.theta_hat, dta['x'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Empirical Example: Choice of heating and central cooling system in California"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **Dataset Overview: House Cooling Systems**  \n",
    "**Alternatives (Heating & Cooling Options)**  \n",
    "- **gcc:** Gas Central Heat with Cooling  \n",
    "- **ecc:** Electric Central Resistance Heat with Cooling  \n",
    "- **erc:** Electric Room Resistance Heat with Cooling  \n",
    "- **hpc:** Electric Heat Pump (always provides cooling)  \n",
    "- **gc:** Gas Central Heat without Cooling  \n",
    "- **ec:** Electric Central Resistance Heat without Cooling  \n",
    "- **er:** Electric Room Resistance Heat without Cooling  \n",
    "- *Note:* Heat pumps (hpc) always provide both heating & cooling.  \n",
    "\n",
    "**Variables & Interpretation**  \n",
    "- **depvar:** Chosen alternative  \n",
    "- **ich:** Installation cost for heating  \n",
    "- **icca:** Installation cost for cooling  \n",
    "- **och:** Operating cost for heating  \n",
    "- **occa:** Operating cost for cooling  \n",
    "- **income:** Annual household income  \n",
    "- **int.cooling:** Dummy = 1 if alternative provides cooling (gcc, ecc, erc, hpc)  \n",
    "- **inc.cooling:** Income × int.cooling (income effect for cooling options)  \n",
    "- **inc.room:** Income × dummy for room resistance heating (erc, er)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Read data in long format and reshape xvars to 3d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt_codes: {'ec': 0, 'ecc': 1, 'er': 2, 'erc': 3, 'gc': 4, 'gcc': 5, 'hpc': 6}\n",
      "Counts of each alternative:\n",
      "gcc    186\n",
      "hpc     26\n",
      "gc      24\n",
      "er       8\n",
      "ecc      4\n",
      "erc      1\n",
      "ec       1\n",
      "Name: idx.id2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the data (long format)\n",
    "df = pd.read_csv(\"HC.csv\",index_col=0)\n",
    "# display(df)\n",
    "# HC.csv is downloaded from \"https://raw.githubusercontent.com/gsbDBI/torch-choice/main/tutorials/public_datasets/HC.csv\"\n",
    "\n",
    "# Encode alternatives as numeric choice indices\n",
    "alt_codes = {alt: idx for idx, alt in enumerate(df['idx.id2'].unique())}\n",
    "df['alt_index'] = df['idx.id2'].map(alt_codes) # create index 0,1,..,J-1 with chosen alternatives\n",
    "print(\"alt_codes:\", alt_codes)\n",
    "\n",
    "# Prepare data for Conditional Logit\n",
    "J = len(alt_codes)  # Number of alternatives\n",
    "N = df.shape[0] // J  # Number of households\n",
    "\n",
    "# dependent variable: index for chosen alternative\n",
    "y = df[df['depvar'] == True]['alt_index'].values  # (N,) \n",
    "\n",
    "# Select covariates that vary across alternatives\n",
    "xvars = ['ich', 'icca', 'och', 'occa', 'inc.room', 'inc.cooling', 'int.cooling']\n",
    "alt=['ec', 'ecc', 'er', 'erc', 'gc', 'gcc', 'hpc']\n",
    "X = df[xvars].values.reshape(N, J, len(xvars))  # Reshape for CL estimation\n",
    "print(f\"Counts of each alternative:\\n{df[df['depvar'] == True]['idx.id2'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimate model with clogit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "Conditional Logit Estimation\n",
      "Initial log-likelihood: -1.945910149055313\n",
      "Initial gradient:\n",
      " [ -3.89552      7.48256     -0.97809143   0.73202286 -12.05714286\n",
      "  16.08571429   0.29657143]\n",
      "Dep. var. : y \n",
      "\n",
      "parnames       theta_hat          se    t-values         jac\n",
      "-----------  -----------  ----------  ----------  ----------\n",
      "ich             -0.85158     0.07879   -10.80835     0.00000\n",
      "icca            -0.25724     0.12697    -2.02600    -0.00001\n",
      "och             -1.35633     0.14740    -9.20187     0.00000\n",
      "occa            -1.41380     1.14907    -1.23039    -0.00000\n",
      "inc.room        -0.58034     0.06326    -9.17434     0.00000\n",
      "inc.cooling      0.31412     0.05399     5.81769    -0.00001\n",
      "int.cooling    -10.62837     5.12930    -2.07209    -0.00000\n",
      "# of observations : 250\n",
      "# log-likelihood. : -180.2864426152086 \n",
      "\n",
      "Iteration info: 45 iterations, 50 evaluations of objective, and 50 evaluations of gradients\n",
      "Elapsed time: 0.0131 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate the model\n",
    "import discrete_choice as ds\n",
    "import mestim as M\n",
    "res=ds.clogit(y, X, deriv=1, xvars=xvars)  # Estimate c-logit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conditional Logit Estimates\n",
    "\n",
    "- **Installation Costs (Heating & Cooling)**  \n",
    "  - Higher installation costs reduce the probability of choosing an alternative.\n",
    "  - **ich (-0.85158)**: Significant and negative, indicating higher heating installation costs deter adoption.  \n",
    "  - **icca (-0.25724)**: Negative, suggesting higher cooling installation costs reduce probability but with lower magnitude.\n",
    "\n",
    "- **Operating Costs (Heating & Cooling)**  \n",
    "  - **och (-1.35633)**: Strong negative effect, confirming higher heating operating costs reduce adoption.  \n",
    "  - **occa (-1.41379)**: Insignificant, implying cooling operating costs are less influential.\n",
    "\n",
    "- **Income Interactions**  \n",
    "  - **inc.room (-0.58034)**: Negative, meaning higher-income households are less likely to choose electric room resistance heating.  \n",
    "  - **inc.cooling (0.31412)**: Positive, suggesting wealthier households prefer alternatives with cooling.  \n",
    "  - **int.cooling (-10.62842)**: Strong negative coefficient, indicating a structural effect in cooling provision.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Average partical effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "APE: Average change in ['p_ec', 'p_ecc', 'p_er', 'p_erc', 'p_gc', 'p_gcc', 'p_hpc']\n",
      "    - w.r.t. change in ['x_ec', 'x_ecc', 'x_er', 'x_erc', 'x_gc', 'x_gcc', 'x_hpc'] \n",
      "    - for attribute m=0 (ich) with coefficient θ_0=[-0.8516]\n",
      "             p_ec       p_ecc        p_er       p_erc        p_gc       p_gcc       p_hpc\n",
      "-----  ----------  ----------  ----------  ----------  ----------  ----------  ----------\n",
      "x_ec     -0.00861     0.00059     0.00062     0.00000     0.00288     0.00261     0.00191\n",
      "x_ecc     0.00059    -0.04061     0.00090     0.00000     0.00135     0.02556     0.01220\n",
      "x_er      0.00062     0.00090    -0.01705     0.00000     0.00520     0.00766     0.00267\n",
      "x_erc     0.00000     0.00000     0.00000    -0.00000     0.00000     0.00000     0.00000\n",
      "x_gc      0.00288     0.00135     0.00520     0.00000    -0.02986     0.01578     0.00466\n",
      "x_gcc     0.00261     0.02556     0.00766     0.00000     0.01578    -0.13872     0.08711\n",
      "x_hpc     0.00191     0.01220     0.00267     0.00000     0.00466     0.08711    -0.10856\n"
     ]
    }
   ],
   "source": [
    "#E_var=ds.APE(res.theta_hat, X, 0, xvars, alternatives=alt)\n",
    "dydx = ds.APE_var(res.theta_hat, X, m=0, xvars=xvars, alternatives=alt) # Compute APE for the first attribute (m=0) - Try other attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Own and Cross Elasticities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Elasticity wrt change in ich\n",
      "             p_ec       p_ecc        p_er       p_erc        p_gc       p_gcc       p_hpc\n",
      "-----  ----------  ----------  ----------  ----------  ----------  ----------  ----------\n",
      "x_ec    -21.51054     0.24569     0.24569     0.24569     0.24569     0.24569     0.24569\n",
      "x_ecc     0.38215    -6.73039     0.38215     0.38215     0.38215     0.38215     0.38215\n",
      "x_er      0.23719     0.23719    -6.37120     0.23719     0.23719     0.23719     0.23719\n",
      "x_erc     0.00000     0.00000     0.00000    -6.71794     0.00000     0.00000     0.00000\n",
      "x_gc      1.45661     1.45661     1.45661     1.45661   -19.80301     1.45661     1.45661\n",
      "x_gcc     3.75649     3.75649     3.75649     3.75649     3.75649    -2.90678     3.75649\n",
      "x_hpc     1.90690     1.90690     1.90690     1.90690     1.90690     1.90690    -7.09186\n",
      "\n",
      "Own elasticity\n",
      "              ich        icca         och        occa    inc.room    inc.cooling    int.cooling\n",
      "-----  ----------  ----------  ----------  ----------  ----------  -------------  -------------\n",
      "x_ec    -21.51054     0.00000    -5.45816     0.00000     0.00000        0.00000        0.00000\n",
      "x_ecc    -6.73039    -6.13901    -5.23722    -3.31858     0.00000       13.17627      -10.01009\n",
      "x_er     -6.37120     0.00000    -5.40331     0.00000   -25.53483        0.00000        0.00000\n",
      "x_erc    -6.71794    -6.52133    -5.60361    -3.51958   -25.95268       14.04733      -10.62837\n",
      "x_gc    -19.80301     0.00000    -2.81123     0.00000     0.00000        0.00000        0.00000\n",
      "x_gcc    -2.90678    -2.75297    -1.31293    -1.48291     0.00000        5.32938       -4.45425\n",
      "x_hpc    -7.09186    -5.02074    -1.58287    -2.71112     0.00000       10.55650       -8.19535\n",
      "\n",
      "Cross-Elasticity\n",
      "              ich        icca         och        occa    inc.room    inc.cooling    int.cooling\n",
      "-----  ----------  ----------  ----------  ----------  ----------  -------------  -------------\n",
      "x_ec      0.24569     0.00000     0.07384     0.00000     0.00000        0.00000        0.00000\n",
      "x_ecc     0.38215     0.38232     0.29477     0.20100     0.00000       -0.87106        0.61828\n",
      "x_er      0.23719     0.00000     0.20030     0.00000     0.41784        0.00000        0.00000\n",
      "x_erc     0.00000     0.00000     0.00000     0.00000     0.00000       -0.00000        0.00000\n",
      "x_gc      1.45661     0.00000     0.24394     0.00000     0.00000        0.00000        0.00000\n",
      "x_gcc     3.75649     3.76837     1.74224     2.03667     0.00000       -8.71795        6.17412\n",
      "x_hpc     1.90690     1.50060     0.46541     0.80846     0.00000       -3.49083        2.43302\n"
     ]
    }
   ],
   "source": [
    "E_var=ds.Ematrix_var(res.theta_hat, X, 0, xvars, alternatives=alt)\n",
    "E_own=ds.Ematrix_own(res.theta_hat, X, xvars, alternatives=alt)\n",
    "E_cross=ds.Ematrix_cross(res.theta_hat, X,  xvars, alternatives=alt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Own and Cross-Elasticities**\n",
    "\n",
    "#### **Own-Elasticities**\n",
    "- **Installation Costs:** Most elastic for **gcc (-21.51)** and **gc (-19.80)**.  \n",
    "- **Operating Costs:**  \n",
    "  - **Heating (och):** Strongest effect for **gcc (-5.46)** and **hpc (-5.60)**.  \n",
    "  - **Cooling (occa):** More elastic for cooling alternatives, **hpc (-3.52)** and **ecc (-3.32)**.  \n",
    "- **Income Effects:**  \n",
    "  - **Room heating (erc, er):** Strong negative effect (-25.53 to -25.95), wealthier households avoid it.  \n",
    "  - **Cooling (inc.cooling):** Positive, confirming income-driven preference.  \n",
    "\n",
    "#### **Cross-Elasticities**\n",
    "- **Identical substitution effects** (logit assumption)  \n",
    "  - Raising heat pump costs affects all other options **equally**, which is **unrealistic**.  \n",
    "  - Demand should shift more towards other **cooling** options, not **non-cooling** alternatives.  \n",
    "- **Negligible Cross-Elasticities for erc**  \n",
    "  - **Only one household chose erc**, leading to near-zero substitution effects.  \n",
    "- **Logit Model Limitation (IIA)**  \n",
    "  - Forces proportional substitution, ignoring closer substitutes.  \n",
    "  - Example: Higher heat pump costs should shift demand to **gcc**, not **gc**.  \n",
    "  - Similarly, **raising och for hpc** should primarily impact other **cooling** options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CCPs measure aggreagte market shares\n",
    "- When using logit models to estimate consumption decisions, \n",
    " **average choice probabilities** represent **market shares**:\n",
    "$$s_j = \\frac{1}{N}\\sum_{i=1}^N\\mathbb{1}({y_i=j})\n",
    "\\qquad\\stackrel{N\\rightarrow\\infty}{\\rightarrow}\\quad P(y=j)$$\n",
    "- So **average marginal effects** measure how **market shares** change.\n",
    "\n",
    "### Standard errors on derived quantities\n",
    "- Marginal effects and elasticties are non linear functions of the estimated parameters. \n",
    "- **Standard errors** of marginal effects and elasticties can be obtained via the **Delta method** or **bootstrap**.\n",
    "- Since probabilities sum up to 1 across alternatives, **marginal effects in the conditional logit sum up to 0**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Least Squres with Cross-Sectional Aggregate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regression using market share data\n",
    "\n",
    "For logit, **average choice probabilities** represent **market shares**:\n",
    "$$s_j = \\frac{1}{N}\\sum_{i=1}^N\\mathbb{1}({y_i=j})\n",
    "\\qquad\\stackrel{N\\rightarrow\\infty}{\\rightarrow}\\quad P(y=j)$$\n",
    "- So **average marginal effects** measure how **market shares** change.\n",
    "\n",
    "- We can estimate $p_{mj}$ using the choice data\n",
    "\n",
    "- If we equate observed market shares, $s_{mj}$ with logit probabilities we get\n",
    "\n",
    "$$s_{mj} = \\dfrac{\\exp\\{x_{mj}\\beta\\}}\n",
    "                                 {\\sum_{k=0}^J\\exp\\{x_{mk}\\beta\\}} \\\\[1em]\n",
    "$$\n",
    "\n",
    "- Easy to transform the choice probabilities for the logit model\n",
    "\n",
    "$$\n",
    "log(s_{mj})-log(s_{m0}) = (x_{mj}-x_{m0})\\beta\n",
    "$$\n",
    "\n",
    "So we can estimate the logit model on market share data using simple regression methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Moving Beyond Conditional Logit – Addressing IIA**  \n",
    "- **IIA** arises due to the assumption that **error terms are independent across alternatives.**\n",
    "- **IIA can be tested** using methods like the **Hausman-McFadden test**.  \n",
    "- **How do we improve the model?**  \n",
    "  - **Nested Logit:** Groups alternatives to allow for **within-group correlation**.  \n",
    "  - **Multinomial Probit:** Allows **general correlation structures in errors**.  \n",
    "  - **Random Coefficients Logit (Mixed Logit):** Introduces **preference heterogeneity** across individuals.  \n",
    "  - **BLP (Berry, Levinsohn, and Pakes):** Addresses IIA for **aggregate market share data** by incorporating **endogenous price and unobserved product characteristics**.  \n",
    "  - **Panel Data Approaches:** Allows **individual-specific variation** in choice behavior over time.  \n",
    "\n",
    "**Next: BLP and Nested Logit – relaxing IIA!**  "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "date": 1602643870.398518,
  "filename": "38_optimization.rst",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "title": "Econometrics B #13"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
